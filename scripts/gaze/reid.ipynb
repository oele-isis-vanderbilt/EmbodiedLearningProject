{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "import pathlib\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "os.environ['DEEPFACE_LOG_LEVEL'] = str(logging.ERROR)\n",
    "from deepface import DeepFace\n",
    "\n",
    "# Constants \n",
    "CWD = pathlib.Path(os.path.abspath(\"\"))\n",
    "GIT_ROOT = CWD.parent.parent\n",
    "DATA_DIR = GIT_ROOT / \"data\" / 'AIED2024'\n",
    "REID_DB = DATA_DIR / 'reid' / 'db'\n",
    "OUTPUT_DIR = DATA_DIR / 'reid' / 'tables'\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18834/18834 [03:53<00:00, 80.80it/s] \n"
     ]
    }
   ],
   "source": [
    "# From video, create the cropped face images\n",
    "def generate_cropped_faces(video_file, tracking_file, output_dir):\n",
    "    assert video_file.exists()\n",
    "    assert tracking_file.exists()\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Load data\n",
    "    cap = cv2.VideoCapture(str(video_file))\n",
    "    LENGTH = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    df = pd.read_csv(tracking_file)\n",
    "\n",
    "    for i in tqdm(range(LENGTH), total=LENGTH):\n",
    "        \n",
    "        # Load frame\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Get the detected faces\n",
    "        detected_faces = df[df['Frame'] == i]\n",
    "\n",
    "        for (j, row) in detected_faces.iterrows():\n",
    "            crop = frame[int(row['Y']):int(row['Y']+row['Height']), int(row['X']):int(row['X']+row['Width'])]\n",
    "            # cv2.imshow('crop', crop)\n",
    "            # cv2.waitKey(0)\n",
    "\n",
    "            cv2.imwrite(str(output_dir / f'frame_{i}_id_{int(row[\"Student_ID\"])}.png'), crop)\n",
    "\n",
    "# generate_cropped_faces(\n",
    "#     DATA_DIR / 'videos' / 'day1' / 'block-a-blue-day1-first-group-cam2.mp4',\n",
    "#     DATA_DIR / 'trackings' / 'Day1Group1Camera2_with_student_IDs.csv',\n",
    "#     DATA_DIR / 'reid' / 'cropped_faces' / 'd1g1'\n",
    "# )\n",
    "# generate_cropped_faces(\n",
    "#     DATA_DIR / 'videos' / 'day1' / 'block-a-blue-day1-second-group-cam2.mp4',\n",
    "#     DATA_DIR / 'trackings' / 'Day1Group2Camera2_with_student_IDs.csv',\n",
    "#     DATA_DIR / 'reid' / 'cropped_faces' / 'd1g2'\n",
    "# )\n",
    "# generate_cropped_faces(\n",
    "#     DATA_DIR / 'videos' / 'day2' / 'block-a-blue-day2-first-group-cam2.mp4',\n",
    "#     DATA_DIR / 'trackings' / 'Day2Group1Camera2_with_student_IDs.csv',\n",
    "#     DATA_DIR / 'reid' / 'cropped_faces' / 'd2g1'\n",
    "# )\n",
    "generate_cropped_faces(\n",
    "    DATA_DIR / 'videos' / 'day2' / 'block-a-blue-day2-second-group-cam2.mp4',\n",
    "    DATA_DIR / 'trackings' / 'Day2Group2Camera2_with_student_IDs.csv',\n",
    "    DATA_DIR / 'reid' / 'cropped_faces' / 'd2g2'\n",
    ")\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13464/13464 [00:10<00:00, 1343.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Df length: 78894, Video length: 13464\n",
      "Exists: 78894/78894 = 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "def sanity_check(video_file: pathlib.Path, tracking_file: pathlib.Path, cropped_face_dir: pathlib.Path):\n",
    "    assert video_file.exists()\n",
    "    assert tracking_file.exists()\n",
    "    assert cropped_face_dir.exists()\n",
    "\n",
    "    # Load the file\n",
    "    df = pd.read_csv(tracking_file)\n",
    "    cap = cv2.VideoCapture(str(video_file))\n",
    "    LENGTH = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Get the face numpy array\n",
    "    exists = 0\n",
    "    for i in tqdm(range(LENGTH), total=LENGTH):\n",
    "        \n",
    "        # Get the detected faces\n",
    "        detected_faces = df[df['Frame'] == i]\n",
    "\n",
    "        for (j, row) in detected_faces.iterrows():\n",
    "            face_crop = cropped_face_dir / f\"frame_{i}_id_{int(row['Student_ID'])}.png\"\n",
    "            if face_crop.exists():\n",
    "                exists += 1\n",
    "\n",
    "    print(f\"Df length: {len(df)}, Video length: {LENGTH}\")\n",
    "    print(f\"Exists: {exists}/{len(df)} = {exists/len(df):.2f}\")\n",
    "\n",
    "sanity_check(\n",
    "    DATA_DIR / 'videos' / 'day1' / 'block-a-blue-day1-first-group-cam2.mp4',\n",
    "    DATA_DIR / 'trackings' / 'Day1Group1Camera2_with_student_IDs.csv',\n",
    "    DATA_DIR / 'reid' / 'cropped_faces' / 'd1g1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cropped images: 52141\n"
     ]
    }
   ],
   "source": [
    "# 52,141 items according to file system\n",
    "dir = DATA_DIR / 'reid' / 'cropped_faces' / 'd1g1'\n",
    "print(f\"Total cropped images: {len([x for x in dir.iterdir()])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12029/12029 [00:54<00:00, 219.44it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reid.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reid.ipynb#W4sZmlsZQ%3D%3D?line=137'>138</a>\u001b[0m \u001b[39m# reid_process(\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reid.ipynb#W4sZmlsZQ%3D%3D?line=138'>139</a>\u001b[0m \u001b[39m#     DATA_DIR / 'videos' / 'day1' / 'block-a-blue-day1-first-group-cam2.mp4',\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reid.ipynb#W4sZmlsZQ%3D%3D?line=139'>140</a>\u001b[0m \u001b[39m#     DATA_DIR / 'trackings' / 'Day1Group1Camera2_with_student_IDs.csv',\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reid.ipynb#W4sZmlsZQ%3D%3D?line=147'>148</a>\u001b[0m \u001b[39m#     OUTPUT_DIR / 'd1g2-cam2.csv'\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reid.ipynb#W4sZmlsZQ%3D%3D?line=148'>149</a>\u001b[0m \u001b[39m# )\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reid.ipynb#W4sZmlsZQ%3D%3D?line=149'>150</a>\u001b[0m reid_process(\n\u001b[1;32m    <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reid.ipynb#W4sZmlsZQ%3D%3D?line=150'>151</a>\u001b[0m     DATA_DIR \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39mvideos\u001b[39m\u001b[39m'\u001b[39m \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39mday2\u001b[39m\u001b[39m'\u001b[39m \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39mblock-a-blue-day2-first-group-cam2.mp4\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reid.ipynb#W4sZmlsZQ%3D%3D?line=151'>152</a>\u001b[0m     DATA_DIR \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtrackings\u001b[39m\u001b[39m'\u001b[39m \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39mDay2Group1Camera2_with_student_IDs.csv\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reid.ipynb#W4sZmlsZQ%3D%3D?line=152'>153</a>\u001b[0m     DATA_DIR \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39mreid\u001b[39m\u001b[39m'\u001b[39m \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcropped_faces\u001b[39m\u001b[39m'\u001b[39m \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39md2g1\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reid.ipynb#W4sZmlsZQ%3D%3D?line=153'>154</a>\u001b[0m     OUTPUT_DIR \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39md2g1-cam2.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reid.ipynb#W4sZmlsZQ%3D%3D?line=154'>155</a>\u001b[0m )\n\u001b[0;32m--> <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reid.ipynb#W4sZmlsZQ%3D%3D?line=155'>156</a>\u001b[0m reid_process(\n\u001b[1;32m    <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reid.ipynb#W4sZmlsZQ%3D%3D?line=156'>157</a>\u001b[0m     DATA_DIR \u001b[39m/\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mvideos\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39m/\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mday2\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39m/\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mblock-a-blue-day2-second-group-cam2.mp4\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m    <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reid.ipynb#W4sZmlsZQ%3D%3D?line=157'>158</a>\u001b[0m     DATA_DIR \u001b[39m/\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mtrackings\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39m/\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mDay2Group2Camera2_with_student_IDs.csv\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m    <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reid.ipynb#W4sZmlsZQ%3D%3D?line=158'>159</a>\u001b[0m     DATA_DIR \u001b[39m/\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mreid\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39m/\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mcropped_faces\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39m/\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39md2g2\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m    <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reid.ipynb#W4sZmlsZQ%3D%3D?line=159'>160</a>\u001b[0m     OUTPUT_DIR \u001b[39m/\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39md2g2-cam2.csv\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[1;32m    <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reid.ipynb#W4sZmlsZQ%3D%3D?line=160'>161</a>\u001b[0m )\n\u001b[1;32m    <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reid.ipynb#W4sZmlsZQ%3D%3D?line=162'>163</a>\u001b[0m cv2\u001b[39m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[1;32m/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reid.ipynb Cell 5\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reid.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39massert\u001b[39;00m video_file\u001b[39m.\u001b[39mexists()\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reid.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39massert\u001b[39;00m tracking_file\u001b[39m.\u001b[39mexists()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reid.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39massert\u001b[39;00m cropped_face_dir\u001b[39m.\u001b[39mexists()\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reid.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Load the file\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reid.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(tracking_file)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "SIZE_REQ = 40\n",
    "distance_THRESHOLD = 0.5\n",
    "INDIVIDUAL_THRESHOLD = 1\n",
    "\n",
    "def reid_process(video_file: pathlib.Path, tracking_file: pathlib.Path, cropped_face_dir: pathlib.Path, output_file: pathlib.Path):\n",
    "    assert video_file.exists()\n",
    "    assert tracking_file.exists()\n",
    "    assert cropped_face_dir.exists()\n",
    "\n",
    "    # Load the file\n",
    "    df = pd.read_csv(tracking_file)\n",
    "    cap = cv2.VideoCapture(str(video_file))\n",
    "    LENGTH = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Create output folder to verify users REID\n",
    "    reid_folder = cropped_face_dir.parent / f\"{cropped_face_dir.name}_reid\"\n",
    "    if reid_folder.exists():\n",
    "        shutil.rmtree(reid_folder)\n",
    "    os.makedirs(reid_folder, exist_ok=True)\n",
    "    for id in ['s1','s2','s3','s4','s5','s6','r1', 'r2','teacher']:\n",
    "        os.makedirs(reid_folder/id, exist_ok=True)\n",
    "\n",
    "    # Create reid container\n",
    "    reid_container = {'cropped_file': [], 'reid': [], 'distance': [], 'comment': []}\n",
    "\n",
    "    tracked_id_to_reid_mapping = {}\n",
    "\n",
    "    # Get the face numpy array\n",
    "    for i in tqdm(range(LENGTH), total=LENGTH):\n",
    "\n",
    "        try:\n",
    "\n",
    "            # Get the detected faces\n",
    "            detected_faces = df[df['Frame'] == i]\n",
    "\n",
    "            # Create container to ensure frame consistency\n",
    "            reid_detections = {}\n",
    "\n",
    "            for (j, row) in detected_faces.iterrows():\n",
    "\n",
    "                tracked_id = int(row['Student_ID'])\n",
    "\n",
    "                if tracked_id in tracked_id_to_reid_mapping:\n",
    "                    reid_container['cropped_file'].append(face_crop.name)\n",
    "                    reid_container['reid'].append(tracked_id_to_reid_mapping[tracked_id])\n",
    "                    reid_container['distance'].append(None)\n",
    "                    reid_container['comment'].append(\"Retracked\")\n",
    "                    continue\n",
    "\n",
    "                filename = f\"frame_{i}_id_{tracked_id}.png\"\n",
    "                face_crop = cropped_face_dir / filename\n",
    "                assert face_crop.exists()\n",
    "                crop = cv2.imread(str(face_crop))\n",
    "\n",
    "                # If the image is to small, not worth the trouble\n",
    "                h,w = crop.shape[:2]\n",
    "                if (h < SIZE_REQ or w < SIZE_REQ):\n",
    "                    reid_container['cropped_file'].append(face_crop.name)\n",
    "                    reid_container['reid'].append(None)\n",
    "                    reid_container['distance'].append(None)\n",
    "                    reid_container['comment'].append(\"image size too small\")\n",
    "                    continue\n",
    "\n",
    "                # cv2.imshow('crop', crop)\n",
    "                # cv2.waitKey(1)\n",
    "\n",
    "                match_df = DeepFace.find(\n",
    "                    img_path=crop,\n",
    "                    db_path=REID_DB,\n",
    "                    model_name=\"Facenet512\",\n",
    "                    distance_metric=\"euclidean_l2\",\n",
    "                    enforce_detection=False,\n",
    "                    silent=True,\n",
    "                    threshold=INDIVIDUAL_THRESHOLD\n",
    "                )[0]\n",
    "\n",
    "                ids = match_df['identity'].str.split(\"/\").str.get(-2)\n",
    "                match_df['identity'] = ids\n",
    "\n",
    "                if len(ids) == 0:\n",
    "                    reid_container['cropped_file'].append(face_crop.name)\n",
    "                    reid_container['reid'].append(None)\n",
    "                    reid_container['distance'].append(None)\n",
    "                    reid_container['comment'].append(\"Failed REID: No Match\")\n",
    "                    pass\n",
    "                else:\n",
    "\n",
    "                    # Possible success\n",
    "                    mode_df = match_df.groupby(\"identity\")['distance'].agg(lambda x: x.mode()[0]).reset_index()\n",
    "\n",
    "                    # Step 3: Find the 'identity' with the lowest mode value of 'distance'\n",
    "                    lowest_mode_identity = mode_df.loc[mode_df['distance'].idxmin()]\n",
    "\n",
    "                    # Compute counts of each 'identity'\n",
    "                    # counts = match_df['identity'].value_counts().reset_index()\n",
    "                    # counts.columns = ['identity', 'count']\n",
    "\n",
    "                    reid_detections[face_crop.name] = {\n",
    "                        \"tracked_id\": tracked_id,\n",
    "                        \"filepath\": face_crop.name,\n",
    "                        \"image\": crop,\n",
    "                        \"reid\": lowest_mode_identity['identity'],\n",
    "                        \"distance\": lowest_mode_identity['distance'],\n",
    "                    }\n",
    "            \n",
    "            # Group by 'reid' and select the row with the highest 'distance' in each group\n",
    "            if reid_detections:\n",
    "                reid_df = pd.DataFrame.from_dict(reid_detections, orient=\"index\")\n",
    "                selected_entries_df = reid_df.groupby('reid', as_index=False).apply(lambda x: x.loc[x['distance'].idxmax()])\n",
    "                selected_entries_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "                # Save the entry\n",
    "                for (k, row) in selected_entries_df.iterrows():\n",
    "                    reid_container['cropped_file'].append(row['filepath'])\n",
    "                    reid_container['reid'].append(row['reid'])\n",
    "                    reid_container['distance'].append(row['distance'])\n",
    "                    reid_container['comment'].append(\"\")\n",
    "\n",
    "                    # Save the image as well\n",
    "                    new_fp = reid_folder / row['reid'] / row['filepath']\n",
    "                    cv2.imwrite(str(new_fp), row['image'])\n",
    "\n",
    "                    # Save in the mapping\n",
    "                    tracked_id_to_reid_mapping[row[\"tracked_id\"]] = row['reid']\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"KeyboardInterrupt detected, saving data\")\n",
    "            break\n",
    "\n",
    "    # Save the container\n",
    "    reid_df = pd.DataFrame(reid_container)\n",
    "    reid_df.to_csv(output_file, index=False)\n",
    "\n",
    "    # Save the mapping from tracked id to REID tag\n",
    "    with open(output_file.parent / f\"{output_file.stem}.json\", \"w\") as f:\n",
    "        json.dump(tracked_id_to_reid_mapping, f, indent=4)\n",
    "\n",
    "# reid_process(\n",
    "#     DATA_DIR / 'videos' / 'day1' / 'block-a-blue-day1-first-group-cam2.mp4',\n",
    "#     DATA_DIR / 'trackings' / 'Day1Group1Camera2_with_student_IDs.csv',\n",
    "#     DATA_DIR / 'reid' / 'cropped_faces' / 'd1g1',\n",
    "#     OUTPUT_DIR / 'd1g1-cam2.csv'\n",
    "# )\n",
    "# reid_process(\n",
    "#     DATA_DIR / 'videos' / 'day1' / 'block-a-blue-day1-second-group-cam2.mp4',\n",
    "#     DATA_DIR / 'trackings' / 'Day1Group2Camera2_with_student_IDs.csv',\n",
    "#     DATA_DIR / 'reid' / 'cropped_faces' / 'd1g2',\n",
    "#     OUTPUT_DIR / 'd1g2-cam2.csv'\n",
    "# )\n",
    "# reid_process(\n",
    "#     DATA_DIR / 'videos' / 'day2' / 'block-a-blue-day2-first-group-cam2.mp4',\n",
    "#     DATA_DIR / 'trackings' / 'Day2Group1Camera2_with_student_IDs.csv',\n",
    "#     DATA_DIR / 'reid' / 'cropped_faces' / 'd2g1',\n",
    "#     OUTPUT_DIR / 'd2g1-cam2.csv'\n",
    "# )\n",
    "reid_process(\n",
    "    DATA_DIR / 'videos' / 'day2' / 'block-a-blue-day2-second-group-cam2.mp4',\n",
    "    DATA_DIR / 'trackings' / 'Day2Group2Camera2_with_student_IDs.csv',\n",
    "    DATA_DIR / 'reid' / 'cropped_faces' / 'd2g2',\n",
    "    OUTPUT_DIR / 'd2g2-cam2.csv'\n",
    ")\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ettk_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

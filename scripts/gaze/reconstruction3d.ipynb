{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a different environment\n",
    "# Instead of opencv-python, use opencv-python-headless (requiring a different environment)\n",
    "\n",
    "# https://github.com/edavalosanaya/plot3d\n",
    "import plot3d\n",
    "\n",
    "# In a separate terminal, run to start the server:\n",
    "# plot3d\n",
    "\n",
    "# Imports\n",
    "import cv2\n",
    "import time\n",
    "import pathlib\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import imutils\n",
    "import open3d as o3d\n",
    "import matplotlib\n",
    "import trimesh\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "# Constants \n",
    "CWD = pathlib.Path(os.path.abspath(\"\"))\n",
    "GIT_ROOT = CWD.parent.parent\n",
    "DATA_DIR = GIT_ROOT / \"data\" / 'AIED2024'\n",
    "\n",
    "# Append ZoeDepth to path\n",
    "import sys\n",
    "sys.path.append('ZoeDepth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a plot\n",
    "plot = plot3d.Plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intrinsics(H,W):\n",
    "    \"\"\"\n",
    "    Intrinsics for a pinhole camera model.\n",
    "    Assume fov of 55 degrees and central principal point.\n",
    "    \"\"\"\n",
    "    f = 0.5 * W / np.tan(0.5 * 55 * np.pi / 180.0)\n",
    "    cx = 0.5 * W\n",
    "    cy = 0.5 * H\n",
    "    return np.array([[f, 0, cx],\n",
    "                     [0, f, cy],\n",
    "                     [0, 0, 1]])\n",
    "\n",
    "def depth_to_points(depth, R=None, t=None):\n",
    "\n",
    "    K = get_intrinsics(depth.shape[1], depth.shape[2])\n",
    "    Kinv = np.linalg.inv(K)\n",
    "    if R is None:\n",
    "        R = np.eye(3)\n",
    "    if t is None:\n",
    "        t = np.zeros(3)\n",
    "\n",
    "    # M converts from your coordinate to PyTorch3D's coordinate system\n",
    "    M = np.eye(3)\n",
    "    M[0, 0] = -1.0\n",
    "    M[1, 1] = -1.0\n",
    "\n",
    "    height, width = depth.shape[1:3]\n",
    "\n",
    "    x = np.arange(width)\n",
    "    y = np.arange(height)\n",
    "    coord = np.stack(np.meshgrid(x, y), -1)\n",
    "    coord = np.concatenate((coord, np.ones_like(coord)[:, :, [0]]), -1)  # z=1\n",
    "    coord = coord.astype(np.float32)\n",
    "    # coord = torch.as_tensor(coord, dtype=torch.float32, device=device)\n",
    "    coord = coord[None]  # bs, h, w, 3\n",
    "\n",
    "    D = depth[:, :, :, None, None]\n",
    "    # print(D.shape, Kinv[None, None, None, ...].shape, coord[:, :, :, :, None].shape )\n",
    "    pts3D_1 = D * Kinv[None, None, None, ...] @ coord[:, :, :, :, None]\n",
    "    # pts3D_1 live in your coordinate system. Convert them to Py3D's\n",
    "    pts3D_1 = M[None, None, None, ...] @ pts3D_1\n",
    "    # from reference to targe tviewpoint\n",
    "    pts3D_2 = R[None, None, None, ...] @ pts3D_1 + t[None, None, None, :, None]\n",
    "    # pts3D_2 = pts3D_1\n",
    "    # depth_2 = pts3D_2[:, :, :, 2, :]  # b,1,h,w\n",
    "    return pts3D_2[:, :, :, :3, 0][0]\n",
    "\n",
    "def depth_edges_mask(depth):\n",
    "    \"\"\"Returns a mask of edges in the depth map.\n",
    "    Args:\n",
    "    depth: 2D numpy array of shape (H, W) with dtype float32.\n",
    "    Returns:\n",
    "    mask: 2D numpy array of shape (H, W) with dtype bool.\n",
    "    \"\"\"\n",
    "    # Compute the x and y gradients of the depth map.\n",
    "    depth_dx, depth_dy = np.gradient(depth)\n",
    "    # Compute the gradient magnitude.\n",
    "    depth_grad = np.sqrt(depth_dx ** 2 + depth_dy ** 2)\n",
    "    # Compute the edge mask.\n",
    "    mask = depth_grad > 0.05\n",
    "    return mask\n",
    "\n",
    "def create_triangles(h, w, mask=None):\n",
    "    \"\"\"Creates mesh triangle indices from a given pixel grid size.\n",
    "        This function is not and need not be differentiable as triangle indices are\n",
    "        fixed.\n",
    "    Args:\n",
    "    h: (int) denoting the height of the image.\n",
    "    w: (int) denoting the width of the image.\n",
    "    Returns:\n",
    "    triangles: 2D numpy array of indices (int) with shape (2(W-1)(H-1) x 3)\n",
    "    \"\"\"\n",
    "    x, y = np.meshgrid(range(w - 1), range(h - 1))\n",
    "    tl = y * w + x\n",
    "    tr = y * w + x + 1\n",
    "    bl = (y + 1) * w + x\n",
    "    br = (y + 1) * w + x + 1\n",
    "    triangles = np.array([tl, bl, tr, br, tr, bl])\n",
    "    triangles = np.transpose(triangles, (1, 2, 0)).reshape(\n",
    "        ((w - 1) * (h - 1) * 2, 3))\n",
    "    if mask is not None:\n",
    "        mask = mask.reshape(-1)\n",
    "        triangles = triangles[mask[triangles].all(1)]\n",
    "    return triangles\n",
    "\n",
    "def get_mesh(image, depth, keep_edges=False):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    pts3d = depth_to_points(depth[None])\n",
    "    pts3d = pts3d.reshape(-1, 3)\n",
    "\n",
    "    # Create a trimesh mesh from the points\n",
    "    # Each pixel is connected to its 4 neighbors\n",
    "    # colors are the RGB values of the image\n",
    "\n",
    "    verts = pts3d.reshape(-1, 3)\n",
    "    image = np.array(image)\n",
    "    if keep_edges:\n",
    "        triangles = create_triangles(image.shape[0], image.shape[1])\n",
    "    else:\n",
    "        triangles = create_triangles(image.shape[0], image.shape[1], mask=~depth_edges_mask(depth))\n",
    "    colors = image.reshape(-1, 3)\n",
    "    mesh = trimesh.Trimesh(vertices=verts, faces=triangles, vertex_colors=colors)\n",
    "\n",
    "    # Save as glb\n",
    "    return mesh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 242/13464 [00:52<48:00,  4.59it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reconstruction3d.ipynb Cell 4\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reconstruction3d.ipynb#W3sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reconstruction3d.ipynb#W3sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m     plot\u001b[39m.\u001b[39mupdate_mesh(\u001b[39m'\u001b[39m\u001b[39mmesh\u001b[39m\u001b[39m'\u001b[39m, mesh)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reconstruction3d.ipynb#W3sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.1\u001b[39;49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Reset the 3D Plot\n",
    "plot.reset()\n",
    "\n",
    "# Add the monitor rectangle\n",
    "SIZE = 125\n",
    "r = R.from_rotvec(np.pi/2 * np.array([-0.2, 0.75, -0.1]))\n",
    "t = np.array([4, 0, -10])*4\n",
    "rt = np.eye(4)\n",
    "rt[:3, :3] = r.as_matrix()\n",
    "rt[:3, 3] = t\n",
    "\n",
    "rect = trimesh.creation.box(extents=np.array([0.5, 0.2, 0.01])*SIZE)\n",
    "rect.visual.face_colors = [1, 0, 0, 0.5]\n",
    "rect.visual.vertex_colors = [1, 0, 0, 0.5]\n",
    "\n",
    "rect.apply_transform(rt)\n",
    "plot.add_mesh('monitor', rect)\n",
    "# plot.update_mesh('monitor', rect)\n",
    "\n",
    "# Load the RGB and depth videos\n",
    "vid_file = DATA_DIR / \"block-a-blue-day1-first-group-cam1.mp4\"\n",
    "assert vid_file.exists()\n",
    "cap = cv2.VideoCapture(str(vid_file))\n",
    "LENGTH = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "depth_file = DATA_DIR / \"depth_test.mp4\"\n",
    "assert depth_file.exists()\n",
    "depth_cap = cv2.VideoCapture(str(depth_file))\n",
    "\n",
    "for i in tqdm(range(LENGTH), total=LENGTH):\n",
    "\n",
    "    # Load frame\n",
    "    r_ret, rgb = cap.read()\n",
    "    d_ret, depth = depth_cap.read()\n",
    "\n",
    "    if not r_ret or not d_ret:\n",
    "        break\n",
    "\n",
    "    depth = cv2.cvtColor(depth, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Resize\n",
    "    rgb = imutils.resize(rgb, width=500)\n",
    "    depth = imutils.resize(depth, width=500)\n",
    "\n",
    "    mesh = get_mesh(rgb, depth, keep_edges=True)\n",
    "    mesh.apply_transform(trimesh.transformations.rotation_matrix(np.pi, [1,0,0]))\n",
    "\n",
    "    # Plot the frame\n",
    "    plot.plot_image(depth)\n",
    "    if i == 0:\n",
    "        plot.add_mesh('mesh', mesh)\n",
    "    else:\n",
    "        plot.update_mesh('mesh', mesh)\n",
    "    time.sleep(0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plot3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "# Use a different environment\n",
    "# Instead of opencv-python, use opencv-python-headless (requiring a different environment)\n",
    "\n",
    "# https://github.com/edavalosanaya/plot3d\n",
    "import plot3d\n",
    "\n",
    "# In a separate terminal, run to start the server:\n",
    "# plot3d\n",
    "\n",
    "# Imports\n",
    "import cv2\n",
    "import time\n",
    "import pathlib\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import imutils\n",
    "import open3d as o3d\n",
    "import matplotlib\n",
    "import trimesh\n",
    "\n",
    "# Constants \n",
    "CWD = pathlib.Path(os.path.abspath(\"\"))\n",
    "GIT_ROOT = CWD.parent.parent\n",
    "DATA_DIR = GIT_ROOT / \"data\" / 'AIED2024'\n",
    "\n",
    "# Append ZoeDepth to path\n",
    "import sys\n",
    "sys.path.append('ZoeDepth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a plot\n",
    "plot = plot3d.Plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intrinsics(H,W):\n",
    "    \"\"\"\n",
    "    Intrinsics for a pinhole camera model.\n",
    "    Assume fov of 55 degrees and central principal point.\n",
    "    \"\"\"\n",
    "    f = 0.5 * W / np.tan(0.5 * 55 * np.pi / 180.0)\n",
    "    cx = 0.5 * W\n",
    "    cy = 0.5 * H\n",
    "    return np.array([[f, 0, cx],\n",
    "                     [0, f, cy],\n",
    "                     [0, 0, 1]])\n",
    "\n",
    "def depth_to_points(depth, R=None, t=None):\n",
    "\n",
    "    K = get_intrinsics(depth.shape[1], depth.shape[2])\n",
    "    Kinv = np.linalg.inv(K)\n",
    "    if R is None:\n",
    "        R = np.eye(3)\n",
    "    if t is None:\n",
    "        t = np.zeros(3)\n",
    "\n",
    "    # M converts from your coordinate to PyTorch3D's coordinate system\n",
    "    M = np.eye(3)\n",
    "    M[0, 0] = -1.0\n",
    "    M[1, 1] = -1.0\n",
    "\n",
    "    height, width = depth.shape[1:3]\n",
    "\n",
    "    x = np.arange(width)\n",
    "    y = np.arange(height)\n",
    "    coord = np.stack(np.meshgrid(x, y), -1)\n",
    "    coord = np.concatenate((coord, np.ones_like(coord)[:, :, [0]]), -1)  # z=1\n",
    "    coord = coord.astype(np.float32)\n",
    "    # coord = torch.as_tensor(coord, dtype=torch.float32, device=device)\n",
    "    coord = coord[None]  # bs, h, w, 3\n",
    "\n",
    "    D = depth[:, :, :, None, None]\n",
    "    # print(D.shape, Kinv[None, None, None, ...].shape, coord[:, :, :, :, None].shape )\n",
    "    pts3D_1 = D * Kinv[None, None, None, ...] @ coord[:, :, :, :, None]\n",
    "    # pts3D_1 live in your coordinate system. Convert them to Py3D's\n",
    "    pts3D_1 = M[None, None, None, ...] @ pts3D_1\n",
    "    # from reference to targe tviewpoint\n",
    "    pts3D_2 = R[None, None, None, ...] @ pts3D_1 + t[None, None, None, :, None]\n",
    "    # pts3D_2 = pts3D_1\n",
    "    # depth_2 = pts3D_2[:, :, :, 2, :]  # b,1,h,w\n",
    "    return pts3D_2[:, :, :, :3, 0][0]\n",
    "\n",
    "def depth_edges_mask(depth):\n",
    "    \"\"\"Returns a mask of edges in the depth map.\n",
    "    Args:\n",
    "    depth: 2D numpy array of shape (H, W) with dtype float32.\n",
    "    Returns:\n",
    "    mask: 2D numpy array of shape (H, W) with dtype bool.\n",
    "    \"\"\"\n",
    "    # Compute the x and y gradients of the depth map.\n",
    "    depth_dx, depth_dy = np.gradient(depth)\n",
    "    # Compute the gradient magnitude.\n",
    "    depth_grad = np.sqrt(depth_dx ** 2 + depth_dy ** 2)\n",
    "    # Compute the edge mask.\n",
    "    mask = depth_grad > 0.05\n",
    "    return mask\n",
    "\n",
    "def create_triangles(h, w, mask=None):\n",
    "    \"\"\"Creates mesh triangle indices from a given pixel grid size.\n",
    "        This function is not and need not be differentiable as triangle indices are\n",
    "        fixed.\n",
    "    Args:\n",
    "    h: (int) denoting the height of the image.\n",
    "    w: (int) denoting the width of the image.\n",
    "    Returns:\n",
    "    triangles: 2D numpy array of indices (int) with shape (2(W-1)(H-1) x 3)\n",
    "    \"\"\"\n",
    "    x, y = np.meshgrid(range(w - 1), range(h - 1))\n",
    "    tl = y * w + x\n",
    "    tr = y * w + x + 1\n",
    "    bl = (y + 1) * w + x\n",
    "    br = (y + 1) * w + x + 1\n",
    "    triangles = np.array([tl, bl, tr, br, tr, bl])\n",
    "    triangles = np.transpose(triangles, (1, 2, 0)).reshape(\n",
    "        ((w - 1) * (h - 1) * 2, 3))\n",
    "    if mask is not None:\n",
    "        mask = mask.reshape(-1)\n",
    "        triangles = triangles[mask[triangles].all(1)]\n",
    "    return triangles\n",
    "\n",
    "def get_mesh(image, depth, keep_edges=False):\n",
    "    pts3d = depth_to_points(depth[None])\n",
    "    pts3d = pts3d.reshape(-1, 3)\n",
    "\n",
    "    # Create a trimesh mesh from the points\n",
    "    # Each pixel is connected to its 4 neighbors\n",
    "    # colors are the RGB values of the image\n",
    "\n",
    "    verts = pts3d.reshape(-1, 3)\n",
    "    image = np.array(image)\n",
    "    if keep_edges:\n",
    "        triangles = create_triangles(image.shape[0], image.shape[1])\n",
    "    else:\n",
    "        triangles = create_triangles(image.shape[0], image.shape[1], mask=~depth_edges_mask(depth))\n",
    "    colors = image.reshape(-1, 3)\n",
    "    mesh = trimesh.Trimesh(vertices=verts, faces=triangles, vertex_colors=colors)\n",
    "\n",
    "    # Save as glb\n",
    "    return mesh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 59/13464 [01:44<6:35:12,  1.77s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reconstruction3d.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reconstruction3d.ipynb#W3sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m depth \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(depth, cv2\u001b[39m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reconstruction3d.ipynb#W3sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# depth = colorize(depth)[:,:,:3]\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reconstruction3d.ipynb#W3sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m mesh \u001b[39m=\u001b[39m get_mesh(rgb, depth, keep_edges\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reconstruction3d.ipynb#W3sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# Create point cloud\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reconstruction3d.ipynb#W3sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# rgb_image = o3d.geometry.Image(rgb)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reconstruction3d.ipynb#W3sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# depth_image = o3d.geometry.Image(depth)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reconstruction3d.ipynb#W3sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reconstruction3d.ipynb#W3sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m# Plot the frame\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reconstruction3d.ipynb#W3sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m plot\u001b[39m.\u001b[39mplot_image(imutils\u001b[39m.\u001b[39mresize(depth, width\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m))\n",
      "\u001b[1;32m/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reconstruction3d.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reconstruction3d.ipynb#W3sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m     triangles \u001b[39m=\u001b[39m create_triangles(image\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], image\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], mask\u001b[39m=\u001b[39m\u001b[39m~\u001b[39mdepth_edges_mask(depth))\n\u001b[1;32m    <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reconstruction3d.ipynb#W3sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m colors \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reconstruction3d.ipynb#W3sZmlsZQ%3D%3D?line=100'>101</a>\u001b[0m mesh \u001b[39m=\u001b[39m trimesh\u001b[39m.\u001b[39;49mTrimesh(vertices\u001b[39m=\u001b[39;49mverts, faces\u001b[39m=\u001b[39;49mtriangles, vertex_colors\u001b[39m=\u001b[39;49mcolors)\n\u001b[1;32m    <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reconstruction3d.ipynb#W3sZmlsZQ%3D%3D?line=102'>103</a>\u001b[0m \u001b[39m# Save as glb\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reconstruction3d.ipynb#W3sZmlsZQ%3D%3D?line=103'>104</a>\u001b[0m \u001b[39mreturn\u001b[39;00m mesh\n",
      "File \u001b[0;32m~/anaconda3/envs/plot3d/lib/python3.10/site-packages/trimesh/base.py:210\u001b[0m, in \u001b[0;36mTrimesh.__init__\u001b[0;34m(self, vertices, faces, face_normals, vertex_normals, face_colors, vertex_colors, face_attributes, vertex_attributes, metadata, process, validate, merge_tex, merge_norm, use_embree, initial_cache, visual, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[39m# process will remove NaN and Inf values and merge vertices\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[39m# if validate, will remove degenerate and duplicate faces\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[39mif\u001b[39;00m process \u001b[39mor\u001b[39;00m validate:\n\u001b[0;32m--> 210\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocess(validate\u001b[39m=\u001b[39;49mvalidate, merge_tex\u001b[39m=\u001b[39;49mmerge_tex, merge_norm\u001b[39m=\u001b[39;49mmerge_norm)\n",
      "File \u001b[0;32m~/anaconda3/envs/plot3d/lib/python3.10/site-packages/trimesh/base.py:261\u001b[0m, in \u001b[0;36mTrimesh.process\u001b[0;34m(self, validate, merge_tex, merge_norm)\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[39m# since none of our process operations moved vertices or faces\u001b[39;00m\n\u001b[1;32m    257\u001b[0m     \u001b[39m# we can keep face and vertex normals in the cache without recomputing\u001b[39;00m\n\u001b[1;32m    258\u001b[0m     \u001b[39m# if faces or vertices have been removed, normals are validated before\u001b[39;00m\n\u001b[1;32m    259\u001b[0m     \u001b[39m# being returned so there is no danger of inconsistent dimensions\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mremove_infinite_values()\n\u001b[0;32m--> 261\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmerge_vertices(merge_tex\u001b[39m=\u001b[39;49mmerge_tex, merge_norm\u001b[39m=\u001b[39;49mmerge_norm)\n\u001b[1;32m    262\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache\u001b[39m.\u001b[39mclear(exclude\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mface_normals\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mvertex_normals\u001b[39m\u001b[39m\"\u001b[39m})\n\u001b[1;32m    264\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetadata[\u001b[39m\"\u001b[39m\u001b[39mprocessed\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/plot3d/lib/python3.10/site-packages/trimesh/base.py:1166\u001b[0m, in \u001b[0;36mTrimesh.merge_vertices\u001b[0;34m(self, merge_tex, merge_norm, digits_vertex, digits_norm, digits_uv)\u001b[0m\n\u001b[1;32m   1137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge_vertices\u001b[39m(\n\u001b[1;32m   1138\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1139\u001b[0m     merge_tex: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1143\u001b[0m     digits_uv: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1144\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1145\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m \u001b[39m    Removes duplicate vertices grouped by position and\u001b[39;00m\n\u001b[1;32m   1147\u001b[0m \u001b[39m    optionally texture coordinate and normal.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1164\u001b[0m \u001b[39m      Number of digits to consider for UV coordinates\u001b[39;00m\n\u001b[1;32m   1165\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1166\u001b[0m     grouping\u001b[39m.\u001b[39;49mmerge_vertices(\n\u001b[1;32m   1167\u001b[0m         mesh\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1168\u001b[0m         merge_tex\u001b[39m=\u001b[39;49mmerge_tex,\n\u001b[1;32m   1169\u001b[0m         merge_norm\u001b[39m=\u001b[39;49mmerge_norm,\n\u001b[1;32m   1170\u001b[0m         digits_vertex\u001b[39m=\u001b[39;49mdigits_vertex,\n\u001b[1;32m   1171\u001b[0m         digits_norm\u001b[39m=\u001b[39;49mdigits_norm,\n\u001b[1;32m   1172\u001b[0m         digits_uv\u001b[39m=\u001b[39;49mdigits_uv,\n\u001b[1;32m   1173\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/plot3d/lib/python3.10/site-packages/trimesh/grouping.py:102\u001b[0m, in \u001b[0;36mmerge_vertices\u001b[0;34m(mesh, merge_tex, merge_norm, digits_vertex, digits_norm, digits_uv)\u001b[0m\n\u001b[1;32m     99\u001b[0m stacked \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mcolumn_stack(stacked)\u001b[39m.\u001b[39mround()\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mint64)\n\u001b[1;32m    101\u001b[0m \u001b[39m# check unique rows of referenced vertices\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m u, i \u001b[39m=\u001b[39m unique_rows(stacked[referenced], keep_order\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    104\u001b[0m \u001b[39m# construct an inverse using the subset\u001b[39;00m\n\u001b[1;32m    105\u001b[0m inverse \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(\u001b[39mlen\u001b[39m(mesh\u001b[39m.\u001b[39mvertices), dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint64)\n",
      "File \u001b[0;32m~/anaconda3/envs/plot3d/lib/python3.10/site-packages/trimesh/grouping.py:435\u001b[0m, in \u001b[0;36munique_rows\u001b[0;34m(data, digits, keep_order)\u001b[0m\n\u001b[1;32m    431\u001b[0m         result\u001b[39m.\u001b[39mappend(inverse)\n\u001b[1;32m    432\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(result)\n\u001b[0;32m--> 435\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39munique_rows\u001b[39m(data, digits\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keep_order\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    436\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[39m    Returns indices of unique rows. It will return the\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[39m    first occurrence of a row that is duplicated:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[39m      Example: data[unique][inverse] == data\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    456\u001b[0m     \u001b[39m# get rows hashable so we can run unique function on it\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Reset the 3D Plot\n",
    "plot.reset()\n",
    "\n",
    "# Load the RGB and depth videos\n",
    "vid_file = DATA_DIR / \"block-a-blue-day1-first-group-cam1.mp4\"\n",
    "assert vid_file.exists()\n",
    "cap = cv2.VideoCapture(str(vid_file))\n",
    "LENGTH = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "depth_file = DATA_DIR / \"depth_test.mp4\"\n",
    "assert depth_file.exists()\n",
    "depth_cap = cv2.VideoCapture(str(depth_file))\n",
    "\n",
    "for i in tqdm(range(LENGTH), total=LENGTH):\n",
    "\n",
    "    # Load frame\n",
    "    r_ret, rgb = cap.read()\n",
    "    d_ret, depth = depth_cap.read()\n",
    "\n",
    "    if not r_ret or not d_ret:\n",
    "        break\n",
    "\n",
    "    depth = cv2.cvtColor(depth, cv2.COLOR_BGR2GRAY)\n",
    "    # depth = colorize(depth)[:,:,:3]\n",
    "\n",
    "    mesh = get_mesh(rgb, depth, keep_edges=True)\n",
    "\n",
    "    # Create point cloud\n",
    "    # rgb_image = o3d.geometry.Image(rgb)\n",
    "    # depth_image = o3d.geometry.Image(depth)\n",
    "    # rgbd = o3d.geometry.RGBDImage.create_from_color_and_depth(rgb_image, depth_image, convert_rgb_to_intensity = False)\n",
    "    # pcd = o3d.geometry.PointCloud.create_from_rgbd_image(\n",
    "    #     rgbd,\n",
    "    #     custom_intrinsics\n",
    "    # )\n",
    "\n",
    "    # flip the orientation, so it looks upright, not upside-down\n",
    "    # pcd.transform([[1,0,0,0],[0,-1,0,0],[0,0,-1,0],[0,0,0,1]])\n",
    "\n",
    "    # Plot the frame\n",
    "    plot.plot_image(imutils.resize(depth, width=500))\n",
    "    plot.add_mesh('mesh', mesh)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plot3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

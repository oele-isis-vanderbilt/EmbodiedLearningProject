{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_52923/691582857.py:20: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "# Use a different environment\n",
    "# Instead of opencv-python, use opencv-python-headless (requiring a different environment)\n",
    "\n",
    "# https://github.com/edavalosanaya/plot3d\n",
    "import plot3d\n",
    "\n",
    "# In a separate terminal, run to start the server:\n",
    "# plot3d\n",
    "\n",
    "# Imports\n",
    "import cv2\n",
    "import time\n",
    "import pathlib\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import imutils\n",
    "import trimesh\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import pandas as pd\n",
    "\n",
    "# Constants \n",
    "CWD = pathlib.Path(os.path.abspath(\"\"))\n",
    "GIT_ROOT = CWD.parent.parent\n",
    "DATA_DIR = GIT_ROOT / \"data\" / 'AIED2024'\n",
    "\n",
    "# Append ZoeDepth to path\n",
    "import sys\n",
    "sys.path.append('ZoeDepth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a plot\n",
    "plot = plot3d.Plot(port=9013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 305/13464 [00:56<40:45,  5.38it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reconstruction3d.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[1;32m    <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reconstruction3d.ipynb#W2sZmlsZQ%3D%3D?line=226'>227</a>\u001b[0m sm_rgb \u001b[39m=\u001b[39m imutils\u001b[39m.\u001b[39mresize(rgb, width\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reconstruction3d.ipynb#W2sZmlsZQ%3D%3D?line=227'>228</a>\u001b[0m sm_depth \u001b[39m=\u001b[39m imutils\u001b[39m.\u001b[39mresize(depth, width\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reconstruction3d.ipynb#W2sZmlsZQ%3D%3D?line=229'>230</a>\u001b[0m mesh \u001b[39m=\u001b[39m get_mesh(sm_rgb, sm_depth, keep_edges\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reconstruction3d.ipynb#W2sZmlsZQ%3D%3D?line=230'>231</a>\u001b[0m mesh\u001b[39m.\u001b[39mapply_transform(trimesh\u001b[39m.\u001b[39mtransformations\u001b[39m.\u001b[39mrotation_matrix(np\u001b[39m.\u001b[39mpi, [\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m]))\n\u001b[1;32m    <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reconstruction3d.ipynb#W2sZmlsZQ%3D%3D?line=232'>233</a>\u001b[0m \u001b[39m# Plot the frame\u001b[39;00m\n",
      "\u001b[1;32m/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reconstruction3d.ipynb Cell 3\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reconstruction3d.ipynb#W2sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_mesh\u001b[39m(image, depth, keep_edges\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reconstruction3d.ipynb#W2sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m     image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(image, cv2\u001b[39m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reconstruction3d.ipynb#W2sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m     pts3d \u001b[39m=\u001b[39m depth_to_points(depth[\u001b[39mNone\u001b[39;49;00m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reconstruction3d.ipynb#W2sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m     pts3d \u001b[39m=\u001b[39m pts3d\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reconstruction3d.ipynb#W2sZmlsZQ%3D%3D?line=90'>91</a>\u001b[0m     \u001b[39m# Create a trimesh mesh from the points\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reconstruction3d.ipynb#W2sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m     \u001b[39m# Each pixel is connected to its 4 neighbors\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reconstruction3d.ipynb#W2sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m     \u001b[39m# colors are the RGB values of the image\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_intrinsics(H,W):\n",
    "    \"\"\"\n",
    "    Intrinsics for a pinhole camera model.\n",
    "    Assume fov of 55 degrees and central principal point.\n",
    "    \"\"\"\n",
    "    f = 0.5 * W / np.tan(0.5 * 55 * np.pi / 180.0)\n",
    "    cx = 0.5 * W\n",
    "    cy = 0.5 * H\n",
    "    return np.array([[f, 0, cx],\n",
    "                     [0, f, cy],\n",
    "                     [0, 0, 1]])\n",
    "\n",
    "def depth_to_points(depth, R=None, t=None):\n",
    "\n",
    "    K = get_intrinsics(depth.shape[1], depth.shape[2])\n",
    "    Kinv = np.linalg.inv(K)\n",
    "    if R is None:\n",
    "        R = np.eye(3)\n",
    "    if t is None:\n",
    "        t = np.zeros(3)\n",
    "\n",
    "    # M converts from your coordinate to PyTorch3D's coordinate system\n",
    "    M = np.eye(3)\n",
    "    M[0, 0] = -1.0\n",
    "    M[1, 1] = -1.0\n",
    "\n",
    "    height, width = depth.shape[1:3]\n",
    "\n",
    "    x = np.arange(width)\n",
    "    y = np.arange(height)\n",
    "    coord = np.stack(np.meshgrid(x, y), -1)\n",
    "    coord = np.concatenate((coord, np.ones_like(coord)[:, :, [0]]), -1)  # z=1\n",
    "    coord = coord.astype(np.float32)\n",
    "    # coord = torch.as_tensor(coord, dtype=torch.float32, device=device)\n",
    "    coord = coord[None]  # bs, h, w, 3\n",
    "\n",
    "    D = depth[:, :, :, None, None]\n",
    "    # print(D.shape, Kinv[None, None, None, ...].shape, coord[:, :, :, :, None].shape )\n",
    "    pts3D_1 = D * Kinv[None, None, None, ...] @ coord[:, :, :, :, None]\n",
    "    # pts3D_1 live in your coordinate system. Convert them to Py3D's\n",
    "    pts3D_1 = M[None, None, None, ...] @ pts3D_1\n",
    "    # from reference to targe tviewpoint\n",
    "    pts3D_2 = R[None, None, None, ...] @ pts3D_1 + t[None, None, None, :, None]\n",
    "    # pts3D_2 = pts3D_1\n",
    "    # depth_2 = pts3D_2[:, :, :, 2, :]  # b,1,h,w\n",
    "    return pts3D_2[:, :, :, :3, 0][0]\n",
    "\n",
    "def depth_edges_mask(depth):\n",
    "    \"\"\"Returns a mask of edges in the depth map.\n",
    "    Args:\n",
    "    depth: 2D numpy array of shape (H, W) with dtype float32.\n",
    "    Returns:\n",
    "    mask: 2D numpy array of shape (H, W) with dtype bool.\n",
    "    \"\"\"\n",
    "    # Compute the x and y gradients of the depth map.\n",
    "    depth_dx, depth_dy = np.gradient(depth)\n",
    "    # Compute the gradient magnitude.\n",
    "    depth_grad = np.sqrt(depth_dx ** 2 + depth_dy ** 2)\n",
    "    # Compute the edge mask.\n",
    "    mask = depth_grad > 0.05\n",
    "    return mask\n",
    "\n",
    "def create_triangles(h, w, mask=None):\n",
    "    \"\"\"Creates mesh triangle indices from a given pixel grid size.\n",
    "        This function is not and need not be differentiable as triangle indices are\n",
    "        fixed.\n",
    "    Args:\n",
    "    h: (int) denoting the height of the image.\n",
    "    w: (int) denoting the width of the image.\n",
    "    Returns:\n",
    "    triangles: 2D numpy array of indices (int) with shape (2(W-1)(H-1) x 3)\n",
    "    \"\"\"\n",
    "    x, y = np.meshgrid(range(w - 1), range(h - 1))\n",
    "    tl = y * w + x\n",
    "    tr = y * w + x + 1\n",
    "    bl = (y + 1) * w + x\n",
    "    br = (y + 1) * w + x + 1\n",
    "    triangles = np.array([tl, bl, tr, br, tr, bl])\n",
    "    triangles = np.transpose(triangles, (1, 2, 0)).reshape(\n",
    "        ((w - 1) * (h - 1) * 2, 3))\n",
    "    if mask is not None:\n",
    "        mask = mask.reshape(-1)\n",
    "        triangles = triangles[mask[triangles].all(1)]\n",
    "    return triangles\n",
    "\n",
    "def get_mesh(image, depth, keep_edges=False):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    pts3d = depth_to_points(depth[None])\n",
    "    pts3d = pts3d.reshape(-1, 3)\n",
    "\n",
    "    # Create a trimesh mesh from the points\n",
    "    # Each pixel is connected to its 4 neighbors\n",
    "    # colors are the RGB values of the image\n",
    "\n",
    "    verts = pts3d.reshape(-1, 3)\n",
    "    image = np.array(image)\n",
    "    if keep_edges:\n",
    "        triangles = create_triangles(image.shape[0], image.shape[1])\n",
    "    else:\n",
    "        triangles = create_triangles(image.shape[0], image.shape[1], mask=~depth_edges_mask(depth))\n",
    "    colors = image.reshape(-1, 3)\n",
    "    mesh = trimesh.Trimesh(vertices=verts, faces=triangles, vertex_colors=colors)\n",
    "\n",
    "    # Save as glb\n",
    "    return mesh\n",
    "\n",
    "def compute_3D_point(x, y, Z, H, W):\n",
    "    \"\"\"\n",
    "    Compute the 3D point in the camera coordinate system from an image coordinate and depth.\n",
    "\n",
    "    Parameters:\n",
    "    - x, y: The image coordinates (pixels)\n",
    "    - Z: The depth value (distance along the camera's viewing axis)\n",
    "    - f_x, f_y: The camera's focal lengths along the X and Y axes (pixels)\n",
    "    - c_x, c_y: The optical center of the camera (pixels)\n",
    "\n",
    "    Returns:\n",
    "    A tuple (X, Y, Z) representing the 3D point in the camera coordinate system.\n",
    "    \"\"\"\n",
    "    # \n",
    "    fy = 0.5 * W / np.tan(0.5 * 55 * np.pi / 180.0)\n",
    "    fx = 0.5 * W / np.tan(0.5 * 55 * np.pi / 180.0)\n",
    "    cx = 0.5 * W\n",
    "    cy = 0.5 * H\n",
    "\n",
    "    # Normalize the 2D coordinates\n",
    "    x_prime = (x - cx) / fx\n",
    "    y_prime = (y - cy) / fy\n",
    "\n",
    "    # Apply the depth to get the 3D point\n",
    "    X = x_prime * Z\n",
    "    Y = y_prime * Z\n",
    "\n",
    "    return np.array([X, Y, Z])\n",
    "    # return (Z, X, Y)\n",
    "    # return (-X, Z, -Y)\n",
    "    # return (Y, X, Z)\n",
    "    # return (Y, Z, X)\n",
    "\n",
    "\n",
    "\n",
    "# Reset the 3D Plot\n",
    "plot.reset()\n",
    "\n",
    "# Add the monitor rectangle\n",
    "SIZE = 125\n",
    "r = R.from_rotvec(np.pi/2 * np.array([-0.2, 0.75, -0.1]))\n",
    "t = np.array([4, 0, -10])*4\n",
    "rt = np.eye(4)\n",
    "rt[:3, :3] = r.as_matrix()\n",
    "rt[:3, 3] = t\n",
    "\n",
    "# rect = trimesh.creation.box(extents=np.array([0.5, 0.2, 0.01])*SIZE)\n",
    "# rect.visual.face_colors = [1, 0, 0, 0.5]\n",
    "# rect.visual.vertex_colors = [1, 0, 0, 0.5]\n",
    "\n",
    "# rect.apply_transform(rt)\n",
    "# plot.add_mesh('monitor', rect)\n",
    "# plot.update_mesh('monitor', rect)\n",
    "\n",
    "sphere = trimesh.creation.uv_sphere(radius=0.5)\n",
    "sphere.visual.face_colors = [1, 0, 0, 0.5]\n",
    "sphere.visual.vertex_colors = [1, 0, 0, 0.5]\n",
    "\n",
    "# Load the gaze vectors and the corresponding CSV with BBox info\n",
    "faces_fp = DATA_DIR / 'trackings' / 'Day1Group1Camera2_with_student_IDs.csv'\n",
    "assert faces_fp.exists()\n",
    "faces_df = pd.read_csv(faces_fp)\n",
    "gaze_vectors_dir = DATA_DIR / 'gaze_vectors'\n",
    "\n",
    "# Load the RGB and depth videos\n",
    "vid_file = DATA_DIR / \"videos\" / \"day1\" / \"block-a-blue-day1-first-group-cam2.mp4\"\n",
    "assert vid_file.exists()\n",
    "cap = cv2.VideoCapture(str(vid_file))\n",
    "LENGTH = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "depth_file = DATA_DIR / 'depths' / 'day1' / \"group1-depth-cam2.mp4\"\n",
    "assert depth_file.exists()\n",
    "depth_cap = cv2.VideoCapture(str(depth_file))\n",
    "\n",
    "delete_after_step = []\n",
    "\n",
    "for i in tqdm(range(LENGTH), total=LENGTH):\n",
    "\n",
    "    # Load frame\n",
    "    r_ret, rgb = cap.read()\n",
    "    d_ret, depth = depth_cap.read()\n",
    "\n",
    "    if not r_ret or not d_ret:\n",
    "        break\n",
    "\n",
    "    depth = cv2.cvtColor(depth, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Get the gaze vector\n",
    "    faces = faces_df[faces_df['Frame'] == i]\n",
    "\n",
    "    j = 0\n",
    "    for (index, face) in faces.iterrows():\n",
    "        # Get the gaze vector\n",
    "        # gaze_vector_pitch_file = gaze_vectors_dir / f'frame{face.frame}_face{face.Face_Index}_pitch.npy'\n",
    "        # gaze_vector_yaw_file = gaze_vectors_dir / f'frame{face.frame}_face{face.Face_Index}_yaw.npy'\n",
    "        # pitch = np.load(gaze_vector_pitch_file)\n",
    "        # yaw = np.load(gaze_vector_yaw_file)\n",
    "\n",
    "        # Compute the centroid of the face\n",
    "        centroid = (face.X + face.Width/2, face.Y + face.Height/2)\n",
    "        centroid_depth = depth[int(centroid[1]), int(centroid[0])]\n",
    "        face_t = compute_3D_point(centroid[0], centroid[1], centroid_depth, depth.shape[0], depth.shape[1])\n",
    "        face_t[-1] = face_t[-1]*-1\n",
    "        face_t[0] = face_t[0]*-1\n",
    "\n",
    "        # Make copy of spher and apply transform\n",
    "        sphere_copy = sphere.copy()\n",
    "        sphere_copy.apply_transform(trimesh.transformations.translation_matrix(face_t))\n",
    "\n",
    "        # Draw spheres in the 3D plot\n",
    "        if f\"face-{j}\" in plot.client.visuals:\n",
    "            plot.update_mesh(f'face-{j}', sphere_copy, correction=False)\n",
    "        else:\n",
    "            plot.add_mesh(f'face-{j}', sphere_copy, correction=False)\n",
    "        j += 1\n",
    "\n",
    "        # Draw in the 2D image\n",
    "        cv2.circle(rgb, (int(centroid[0]), int(centroid[1])), 5, (0, 255, 0), -1)\n",
    "            \n",
    "    # Resize\n",
    "    sm_rgb = imutils.resize(rgb, width=500)\n",
    "    sm_depth = imutils.resize(depth, width=500)\n",
    "\n",
    "    mesh = get_mesh(sm_rgb, sm_depth, keep_edges=True)\n",
    "    mesh.apply_transform(trimesh.transformations.rotation_matrix(np.pi, [1,0,0]))\n",
    "\n",
    "    # Plot the frame\n",
    "    plot.plot_image(sm_rgb)\n",
    "    if i == 0:\n",
    "        plot.add_mesh('mesh', mesh, correction=False)\n",
    "    else:\n",
    "        plot.update_mesh('mesh', mesh, correction=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plot3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

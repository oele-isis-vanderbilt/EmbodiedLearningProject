{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a different environment\n",
    "# Instead of opencv-python, use opencv-python-headless (requiring a different environment)\n",
    "\n",
    "# https://github.com/edavalosanaya/plot3d\n",
    "import plot3d\n",
    "\n",
    "# In a separate terminal, run to start the server:\n",
    "# plot3d\n",
    "\n",
    "# Imports\n",
    "import cv2\n",
    "import time\n",
    "import pathlib\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import imutils\n",
    "import trimesh\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import pandas as pd\n",
    "\n",
    "# Constants \n",
    "CWD = pathlib.Path(os.path.abspath(\"\"))\n",
    "GIT_ROOT = CWD.parent.parent\n",
    "DATA_DIR = GIT_ROOT / \"data\" / 'AIED2024'\n",
    "\n",
    "# Append ZoeDepth to path\n",
    "import sys\n",
    "sys.path.append('ZoeDepth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a plot\n",
    "plot = plot3d.Plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intrinsics(H,W):\n",
    "    \"\"\"\n",
    "    Intrinsics for a pinhole camera model.\n",
    "    Assume fov of 55 degrees and central principal point.\n",
    "    \"\"\"\n",
    "    f = 0.5 * W / np.tan(0.5 * 55 * np.pi / 180.0)\n",
    "    cx = 0.5 * W\n",
    "    cy = 0.5 * H\n",
    "    return np.array([[f, 0, cx],\n",
    "                     [0, f, cy],\n",
    "                     [0, 0, 1]])\n",
    "\n",
    "def depth_to_points(depth, R=None, t=None):\n",
    "\n",
    "    K = get_intrinsics(depth.shape[1], depth.shape[2])\n",
    "    Kinv = np.linalg.inv(K)\n",
    "    if R is None:\n",
    "        R = np.eye(3)\n",
    "    if t is None:\n",
    "        t = np.zeros(3)\n",
    "\n",
    "    # M converts from your coordinate to PyTorch3D's coordinate system\n",
    "    M = np.eye(3)\n",
    "    M[0, 0] = -1.0\n",
    "    M[1, 1] = -1.0\n",
    "\n",
    "    height, width = depth.shape[1:3]\n",
    "\n",
    "    x = np.arange(width)\n",
    "    y = np.arange(height)\n",
    "    coord = np.stack(np.meshgrid(x, y), -1)\n",
    "    coord = np.concatenate((coord, np.ones_like(coord)[:, :, [0]]), -1)  # z=1\n",
    "    coord = coord.astype(np.float32)\n",
    "    # coord = torch.as_tensor(coord, dtype=torch.float32, device=device)\n",
    "    coord = coord[None]  # bs, h, w, 3\n",
    "\n",
    "    D = depth[:, :, :, None, None]\n",
    "    # print(D.shape, Kinv[None, None, None, ...].shape, coord[:, :, :, :, None].shape )\n",
    "    pts3D_1 = D * Kinv[None, None, None, ...] @ coord[:, :, :, :, None]\n",
    "    # pts3D_1 live in your coordinate system. Convert them to Py3D's\n",
    "    pts3D_1 = M[None, None, None, ...] @ pts3D_1\n",
    "    # from reference to targe tviewpoint\n",
    "    pts3D_2 = R[None, None, None, ...] @ pts3D_1 + t[None, None, None, :, None]\n",
    "    # pts3D_2 = pts3D_1\n",
    "    # depth_2 = pts3D_2[:, :, :, 2, :]  # b,1,h,w\n",
    "    return pts3D_2[:, :, :, :3, 0][0]\n",
    "\n",
    "def depth_edges_mask(depth):\n",
    "    \"\"\"Returns a mask of edges in the depth map.\n",
    "    Args:\n",
    "    depth: 2D numpy array of shape (H, W) with dtype float32.\n",
    "    Returns:\n",
    "    mask: 2D numpy array of shape (H, W) with dtype bool.\n",
    "    \"\"\"\n",
    "    # Compute the x and y gradients of the depth map.\n",
    "    depth_dx, depth_dy = np.gradient(depth)\n",
    "    # Compute the gradient magnitude.\n",
    "    depth_grad = np.sqrt(depth_dx ** 2 + depth_dy ** 2)\n",
    "    # Compute the edge mask.\n",
    "    mask = depth_grad > 0.05\n",
    "    return mask\n",
    "\n",
    "def create_triangles(h, w, mask=None):\n",
    "    \"\"\"Creates mesh triangle indices from a given pixel grid size.\n",
    "        This function is not and need not be differentiable as triangle indices are\n",
    "        fixed.\n",
    "    Args:\n",
    "    h: (int) denoting the height of the image.\n",
    "    w: (int) denoting the width of the image.\n",
    "    Returns:\n",
    "    triangles: 2D numpy array of indices (int) with shape (2(W-1)(H-1) x 3)\n",
    "    \"\"\"\n",
    "    x, y = np.meshgrid(range(w - 1), range(h - 1))\n",
    "    tl = y * w + x\n",
    "    tr = y * w + x + 1\n",
    "    bl = (y + 1) * w + x\n",
    "    br = (y + 1) * w + x + 1\n",
    "    triangles = np.array([tl, bl, tr, br, tr, bl])\n",
    "    triangles = np.transpose(triangles, (1, 2, 0)).reshape(\n",
    "        ((w - 1) * (h - 1) * 2, 3))\n",
    "    if mask is not None:\n",
    "        mask = mask.reshape(-1)\n",
    "        triangles = triangles[mask[triangles].all(1)]\n",
    "    return triangles\n",
    "\n",
    "def get_mesh(image, depth, keep_edges=False):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    pts3d = depth_to_points(depth[None])\n",
    "    pts3d = pts3d.reshape(-1, 3)\n",
    "\n",
    "    # Create a trimesh mesh from the points\n",
    "    # Each pixel is connected to its 4 neighbors\n",
    "    # colors are the RGB values of the image\n",
    "\n",
    "    verts = pts3d.reshape(-1, 3)\n",
    "    image = np.array(image)\n",
    "    if keep_edges:\n",
    "        triangles = create_triangles(image.shape[0], image.shape[1])\n",
    "    else:\n",
    "        triangles = create_triangles(image.shape[0], image.shape[1], mask=~depth_edges_mask(depth))\n",
    "    colors = image.reshape(-1, 3)\n",
    "    mesh = trimesh.Trimesh(vertices=verts, faces=triangles, vertex_colors=colors)\n",
    "\n",
    "    # Save as glb\n",
    "    return mesh\n",
    "\n",
    "def compute_3D_point(x, y, Z, H, W):\n",
    "    \"\"\"\n",
    "    Compute the 3D point in the camera coordinate system from an image coordinate and depth.\n",
    "\n",
    "    Parameters:\n",
    "    - x, y: The image coordinates (pixels)\n",
    "    - Z: The depth value (distance along the camera's viewing axis)\n",
    "    - f_x, f_y: The camera's focal lengths along the X and Y axes (pixels)\n",
    "    - c_x, c_y: The optical center of the camera (pixels)\n",
    "\n",
    "    Returns:\n",
    "    A tuple (X, Y, Z) representing the 3D point in the camera coordinate system.\n",
    "    \"\"\"\n",
    "    # \n",
    "    fy = 0.5 * W / np.tan(0.5 * 55 * np.pi / 180.0)\n",
    "    fx = 0.5 * W / np.tan(0.5 * 55 * np.pi / 180.0)\n",
    "    cx = 0.5 * W\n",
    "    cy = 0.5 * H\n",
    "\n",
    "    # Normalize the 2D coordinates\n",
    "    x_prime = (x - cx) / fx\n",
    "    y_prime = (y - cy) / fy\n",
    "\n",
    "    # Apply the depth to get the 3D point\n",
    "    X = x_prime * Z\n",
    "    Y = y_prime * Z\n",
    "\n",
    "    return (X, Y, Z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 120/13464 [00:22<41:03,  5.42it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reconstruction3d.ipynb Cell 4\u001b[0m line \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reconstruction3d.ipynb#W3sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m sm_rgb \u001b[39m=\u001b[39m imutils\u001b[39m.\u001b[39mresize(rgb, width\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reconstruction3d.ipynb#W3sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m sm_depth \u001b[39m=\u001b[39m imutils\u001b[39m.\u001b[39mresize(depth, width\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reconstruction3d.ipynb#W3sZmlsZQ%3D%3D?line=90'>91</a>\u001b[0m mesh \u001b[39m=\u001b[39m get_mesh(sm_rgb, sm_depth, keep_edges\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reconstruction3d.ipynb#W3sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m mesh\u001b[39m.\u001b[39mapply_transform(trimesh\u001b[39m.\u001b[39mtransformations\u001b[39m.\u001b[39mrotation_matrix(np\u001b[39m.\u001b[39mpi, [\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m]))\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reconstruction3d.ipynb#W3sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m \u001b[39m# Plot the frame\u001b[39;00m\n",
      "\u001b[1;32m/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reconstruction3d.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reconstruction3d.ipynb#W3sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m     triangles \u001b[39m=\u001b[39m create_triangles(image\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], image\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], mask\u001b[39m=\u001b[39m\u001b[39m~\u001b[39mdepth_edges_mask(depth))\n\u001b[1;32m    <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reconstruction3d.ipynb#W3sZmlsZQ%3D%3D?line=100'>101</a>\u001b[0m colors \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reconstruction3d.ipynb#W3sZmlsZQ%3D%3D?line=101'>102</a>\u001b[0m mesh \u001b[39m=\u001b[39m trimesh\u001b[39m.\u001b[39;49mTrimesh(vertices\u001b[39m=\u001b[39;49mverts, faces\u001b[39m=\u001b[39;49mtriangles, vertex_colors\u001b[39m=\u001b[39;49mcolors)\n\u001b[1;32m    <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reconstruction3d.ipynb#W3sZmlsZQ%3D%3D?line=103'>104</a>\u001b[0m \u001b[39m# Save as glb\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/media/nicole/WD_MyPassport/GitHub/EmbodiedLearningProject/scripts/gaze/reconstruction3d.ipynb#W3sZmlsZQ%3D%3D?line=104'>105</a>\u001b[0m \u001b[39mreturn\u001b[39;00m mesh\n",
      "File \u001b[0;32m~/anaconda3/envs/plot3d/lib/python3.10/site-packages/trimesh/base.py:210\u001b[0m, in \u001b[0;36mTrimesh.__init__\u001b[0;34m(self, vertices, faces, face_normals, vertex_normals, face_colors, vertex_colors, face_attributes, vertex_attributes, metadata, process, validate, merge_tex, merge_norm, use_embree, initial_cache, visual, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[39m# process will remove NaN and Inf values and merge vertices\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[39m# if validate, will remove degenerate and duplicate faces\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[39mif\u001b[39;00m process \u001b[39mor\u001b[39;00m validate:\n\u001b[0;32m--> 210\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocess(validate\u001b[39m=\u001b[39;49mvalidate, merge_tex\u001b[39m=\u001b[39;49mmerge_tex, merge_norm\u001b[39m=\u001b[39;49mmerge_norm)\n",
      "File \u001b[0;32m~/anaconda3/envs/plot3d/lib/python3.10/site-packages/trimesh/base.py:261\u001b[0m, in \u001b[0;36mTrimesh.process\u001b[0;34m(self, validate, merge_tex, merge_norm)\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[39m# since none of our process operations moved vertices or faces\u001b[39;00m\n\u001b[1;32m    257\u001b[0m     \u001b[39m# we can keep face and vertex normals in the cache without recomputing\u001b[39;00m\n\u001b[1;32m    258\u001b[0m     \u001b[39m# if faces or vertices have been removed, normals are validated before\u001b[39;00m\n\u001b[1;32m    259\u001b[0m     \u001b[39m# being returned so there is no danger of inconsistent dimensions\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mremove_infinite_values()\n\u001b[0;32m--> 261\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmerge_vertices(merge_tex\u001b[39m=\u001b[39;49mmerge_tex, merge_norm\u001b[39m=\u001b[39;49mmerge_norm)\n\u001b[1;32m    262\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache\u001b[39m.\u001b[39mclear(exclude\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mface_normals\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mvertex_normals\u001b[39m\u001b[39m\"\u001b[39m})\n\u001b[1;32m    264\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetadata[\u001b[39m\"\u001b[39m\u001b[39mprocessed\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/plot3d/lib/python3.10/site-packages/trimesh/base.py:1166\u001b[0m, in \u001b[0;36mTrimesh.merge_vertices\u001b[0;34m(self, merge_tex, merge_norm, digits_vertex, digits_norm, digits_uv)\u001b[0m\n\u001b[1;32m   1137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge_vertices\u001b[39m(\n\u001b[1;32m   1138\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1139\u001b[0m     merge_tex: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1143\u001b[0m     digits_uv: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1144\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1145\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m \u001b[39m    Removes duplicate vertices grouped by position and\u001b[39;00m\n\u001b[1;32m   1147\u001b[0m \u001b[39m    optionally texture coordinate and normal.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1164\u001b[0m \u001b[39m      Number of digits to consider for UV coordinates\u001b[39;00m\n\u001b[1;32m   1165\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1166\u001b[0m     grouping\u001b[39m.\u001b[39;49mmerge_vertices(\n\u001b[1;32m   1167\u001b[0m         mesh\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1168\u001b[0m         merge_tex\u001b[39m=\u001b[39;49mmerge_tex,\n\u001b[1;32m   1169\u001b[0m         merge_norm\u001b[39m=\u001b[39;49mmerge_norm,\n\u001b[1;32m   1170\u001b[0m         digits_vertex\u001b[39m=\u001b[39;49mdigits_vertex,\n\u001b[1;32m   1171\u001b[0m         digits_norm\u001b[39m=\u001b[39;49mdigits_norm,\n\u001b[1;32m   1172\u001b[0m         digits_uv\u001b[39m=\u001b[39;49mdigits_uv,\n\u001b[1;32m   1173\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/plot3d/lib/python3.10/site-packages/trimesh/grouping.py:102\u001b[0m, in \u001b[0;36mmerge_vertices\u001b[0;34m(mesh, merge_tex, merge_norm, digits_vertex, digits_norm, digits_uv)\u001b[0m\n\u001b[1;32m     99\u001b[0m stacked \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mcolumn_stack(stacked)\u001b[39m.\u001b[39mround()\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mint64)\n\u001b[1;32m    101\u001b[0m \u001b[39m# check unique rows of referenced vertices\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m u, i \u001b[39m=\u001b[39m unique_rows(stacked[referenced], keep_order\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    104\u001b[0m \u001b[39m# construct an inverse using the subset\u001b[39;00m\n\u001b[1;32m    105\u001b[0m inverse \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(\u001b[39mlen\u001b[39m(mesh\u001b[39m.\u001b[39mvertices), dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint64)\n",
      "File \u001b[0;32m~/anaconda3/envs/plot3d/lib/python3.10/site-packages/trimesh/grouping.py:463\u001b[0m, in \u001b[0;36munique_rows\u001b[0;34m(data, digits, keep_order)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[39m# we are throwing away the first value which is the\u001b[39;00m\n\u001b[1;32m    460\u001b[0m \u001b[39m# garbage row-hash and only returning index and inverse\u001b[39;00m\n\u001b[1;32m    461\u001b[0m \u001b[39mif\u001b[39;00m keep_order:\n\u001b[1;32m    462\u001b[0m     \u001b[39m# keeps order of original occurrence\u001b[39;00m\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m unique_ordered(rows, return_index\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, return_inverse\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)[\u001b[39m1\u001b[39m:]\n\u001b[1;32m    464\u001b[0m \u001b[39m# returns values sorted by row-hash but since our row-hash\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \u001b[39m# were pretty much garbage the sort order isn't meaningful\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39munique(rows, return_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, return_inverse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)[\u001b[39m1\u001b[39m:]\n",
      "File \u001b[0;32m~/anaconda3/envs/plot3d/lib/python3.10/site-packages/trimesh/grouping.py:291\u001b[0m, in \u001b[0;36munique_ordered\u001b[0;34m(data, return_index, return_inverse)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[39mReturns the same as np.unique, but ordered as per the\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \u001b[39mfirst occurrence of the unique value in data.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mOut[3]: array([0, 3, 4, 1, 2])\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[39m# uniques are the values, sorted\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[39m# index is the value in the original `data`\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[39m# i.e. `data[index] == unique`\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[39m# inverse is how to re-construct `data` from `unique`\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[39m# i.e. `unique[inverse] == data`\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m unique, index, inverse \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49munique(data, return_index\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, return_inverse\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    293\u001b[0m \u001b[39m# we want to maintain the original index order\u001b[39;00m\n\u001b[1;32m    294\u001b[0m order \u001b[39m=\u001b[39m index\u001b[39m.\u001b[39margsort()\n",
      "File \u001b[0;32m~/anaconda3/envs/plot3d/lib/python3.10/site-packages/numpy/lib/arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[1;32m    272\u001b[0m ar \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masanyarray(ar)\n\u001b[1;32m    273\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m     ret \u001b[39m=\u001b[39m _unique1d(ar, return_index, return_inverse, return_counts, \n\u001b[1;32m    275\u001b[0m                     equal_nan\u001b[39m=\u001b[39;49mequal_nan)\n\u001b[1;32m    276\u001b[0m     \u001b[39mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[1;32m    278\u001b[0m \u001b[39m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/plot3d/lib/python3.10/site-packages/numpy/lib/arraysetops.py:358\u001b[0m, in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[1;32m    356\u001b[0m     ret \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (perm[mask],)\n\u001b[1;32m    357\u001b[0m \u001b[39mif\u001b[39;00m return_inverse:\n\u001b[0;32m--> 358\u001b[0m     imask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mcumsum(mask) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    359\u001b[0m     inv_idx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(mask\u001b[39m.\u001b[39mshape, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mintp)\n\u001b[1;32m    360\u001b[0m     inv_idx[perm] \u001b[39m=\u001b[39m imask\n",
      "File \u001b[0;32m~/anaconda3/envs/plot3d/lib/python3.10/site-packages/numpy/core/fromnumeric.py:2586\u001b[0m, in \u001b[0;36mcumsum\u001b[0;34m(a, axis, dtype, out)\u001b[0m\n\u001b[1;32m   2512\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_cumsum_dispatcher)\n\u001b[1;32m   2513\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcumsum\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   2514\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2515\u001b[0m \u001b[39m    Return the cumulative sum of the elements along a given axis.\u001b[39;00m\n\u001b[1;32m   2516\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2584\u001b[0m \n\u001b[1;32m   2585\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2586\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapfunc(a, \u001b[39m'\u001b[39;49m\u001b[39mcumsum\u001b[39;49m\u001b[39m'\u001b[39;49m, axis\u001b[39m=\u001b[39;49maxis, dtype\u001b[39m=\u001b[39;49mdtype, out\u001b[39m=\u001b[39;49mout)\n",
      "File \u001b[0;32m~/anaconda3/envs/plot3d/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m     58\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m     60\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[39m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     \u001b[39m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[39m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     \u001b[39m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Reset the 3D Plot\n",
    "plot.reset()\n",
    "\n",
    "# Add the monitor rectangle\n",
    "SIZE = 125\n",
    "r = R.from_rotvec(np.pi/2 * np.array([-0.2, 0.75, -0.1]))\n",
    "t = np.array([4, 0, -10])*4\n",
    "rt = np.eye(4)\n",
    "rt[:3, :3] = r.as_matrix()\n",
    "rt[:3, 3] = t\n",
    "\n",
    "rect = trimesh.creation.box(extents=np.array([0.5, 0.2, 0.01])*SIZE)\n",
    "rect.visual.face_colors = [1, 0, 0, 0.5]\n",
    "rect.visual.vertex_colors = [1, 0, 0, 0.5]\n",
    "\n",
    "rect.apply_transform(rt)\n",
    "plot.add_mesh('monitor', rect)\n",
    "# plot.update_mesh('monitor', rect)\n",
    "\n",
    "sphere = trimesh.creation.uv_sphere(radius=0.5)\n",
    "sphere.visual.face_colors = [0, 1, 0, 0.5]\n",
    "sphere.visual.vertex_colors = [0, 1, 0, 0.5]\n",
    "\n",
    "# Load the gaze vectors and the corresponding CSV with BBox info\n",
    "faces_fp = DATA_DIR / 'Cam1_SampleData_Analysis' / 'C1Sample.csv'\n",
    "assert faces_fp.exists()\n",
    "faces_df = pd.read_csv(faces_fp)\n",
    "gaze_vectors_dir = DATA_DIR / 'gaze_vectors'\n",
    "\n",
    "# Load the RGB and depth videos\n",
    "vid_file = DATA_DIR / \"block-a-blue-day1-first-group-cam1.mp4\"\n",
    "assert vid_file.exists()\n",
    "cap = cv2.VideoCapture(str(vid_file))\n",
    "LENGTH = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "depth_file = DATA_DIR / \"depth_test.mp4\"\n",
    "assert depth_file.exists()\n",
    "depth_cap = cv2.VideoCapture(str(depth_file))\n",
    "\n",
    "delete_after_step = []\n",
    "\n",
    "for i in tqdm(range(LENGTH), total=LENGTH):\n",
    "\n",
    "    # Things to clear\n",
    "    # for name in delete_after_step:\n",
    "    #     plot.delete_visual(name)\n",
    "    # delete_after_step = []\n",
    "\n",
    "    # Load frame\n",
    "    r_ret, rgb = cap.read()\n",
    "    d_ret, depth = depth_cap.read()\n",
    "\n",
    "    if not r_ret or not d_ret:\n",
    "        break\n",
    "\n",
    "    depth = cv2.cvtColor(depth, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Get the gaze vector\n",
    "    faces = faces_df[faces_df['Frame'] == i]\n",
    "\n",
    "    j = 0\n",
    "    for (index, face) in faces.iterrows():\n",
    "        # Get the gaze vector\n",
    "        # gaze_vector_file = gaze_vectors_dir / f'{face.frame}_{face.Face_Index}.npy'\n",
    "        # gaze_vector = np.load(gaze_vector_file)\n",
    "\n",
    "        # Compute the centroid of the face\n",
    "        centroid = (face.X + face.Width/2, face.Y + face.Height/2)\n",
    "        centroid_depth = depth[int(centroid[1]), int(centroid[0])]*-1\n",
    "        face_t = compute_3D_point(centroid[0], centroid[1], centroid_depth, depth.shape[0], depth.shape[1])\n",
    "\n",
    "        # Make copy of spher and apply transform\n",
    "        sphere_copy = sphere.copy()\n",
    "        sphere_copy.apply_transform(trimesh.transformations.translation_matrix(face_t))\n",
    "\n",
    "        # Draw spheres in the 3D plot\n",
    "        if f\"face-{j}\" in plot.client.visuals:\n",
    "            plot.update_mesh(f'face-{j}', sphere_copy)\n",
    "        else:\n",
    "            plot.add_mesh(f'face-{j}', sphere_copy)\n",
    "        j += 1\n",
    "        # delete_after_step.append(f'face-0')\n",
    "\n",
    "        # Draw in the 2D image\n",
    "        cv2.circle(rgb, (int(centroid[0]), int(centroid[1])), 5, (0, 255, 0), -1)\n",
    "            \n",
    "    # Resize\n",
    "    sm_rgb = imutils.resize(rgb, width=500)\n",
    "    sm_depth = imutils.resize(depth, width=500)\n",
    "\n",
    "    mesh = get_mesh(sm_rgb, sm_depth, keep_edges=True)\n",
    "    mesh.apply_transform(trimesh.transformations.rotation_matrix(np.pi, [1,0,0]))\n",
    "\n",
    "    # Plot the frame\n",
    "    plot.plot_image(sm_rgb)\n",
    "    if i == 0:\n",
    "        plot.add_mesh('mesh', mesh)\n",
    "    else:\n",
    "        plot.update_mesh('mesh', mesh)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plot3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

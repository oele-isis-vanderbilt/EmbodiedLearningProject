{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's process the GEM-STEP logs and reconstruct the game state for Photosynthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pathlib\n",
    "import os\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, Literal, Optional, Tuple\n",
    "import json\n",
    "\n",
    "from dataclasses_json import DataClassJsonMixin\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Constants \n",
    "CWD = pathlib.Path(os.path.abspath(\"\"))\n",
    "GIT_ROOT = CWD.parent\n",
    "DATA_DIR = GIT_ROOT / \"data\" / 'SSMVSpring23'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2276323/2276323 [00:25<00:00, 88154.20it/s]\n",
      " 99%|█████████▉| 625970/630194 [00:06<00:00, 91627.43it/s]\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Extra data: line 1 column 4 (char 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 113\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mdir\u001b[39m \u001b[38;5;129;01min\u001b[39;00m (DATA_DIR \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogs\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39miterdir():\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mdir\u001b[39m\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m--> 113\u001b[0m         \u001b[43mlog_preprocessing\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdir\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 33\u001b[0m, in \u001b[0;36mlog_preprocessing\u001b[0;34m(dir)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# If NET:DISPLAY_LIST, process the JSON format\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNET:DISPLAY_LIST\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m elements:\n\u001b[0;32m---> 33\u001b[0m     json_element \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43melements\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m# Filter to only get the actors that are students\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     results \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[39m=\u001b[39m s\u001b[39m.\u001b[39mdecode(detect_encoding(s), \u001b[39m'\u001b[39m\u001b[39msurrogatepass\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_decoder\u001b[39m.\u001b[39;49mdecode(s)\n\u001b[1;32m    347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/json/decoder.py:340\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    338\u001b[0m end \u001b[39m=\u001b[39m _w(s, end)\u001b[39m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m \u001b[39mif\u001b[39;00m end \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(s):\n\u001b[0;32m--> 340\u001b[0m     \u001b[39mraise\u001b[39;00m JSONDecodeError(\u001b[39m\"\u001b[39m\u001b[39mExtra data\u001b[39m\u001b[39m\"\u001b[39m, s, end)\n\u001b[1;32m    341\u001b[0m \u001b[39mreturn\u001b[39;00m obj\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Extra data: line 1 column 4 (char 3)"
     ]
    }
   ],
   "source": [
    "# Perform log pre-processing (Step #1) (combining and converting .txt to .csv)\n",
    "def log_preprocessing(dir):\n",
    "\n",
    "    output_file = dir / 'game_logs.csv'\n",
    "    # if output_file.exists():\n",
    "    #     return\n",
    "\n",
    "    # Combine all .txt files into one .csv file\n",
    "    txt_files = [file for file in dir.iterdir() if file.suffix == '.txt']\n",
    "    dfs = []\n",
    "    for file in txt_files:\n",
    "        \n",
    "        # Won't work - error loading file\n",
    "        # df = pd.read_csv(file, sep='\\t', header=None)\n",
    "        # dfs.append(df)\n",
    "\n",
    "        with open(file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "            pass_config_line = False\n",
    "            columns = {'datetime': [], 'event_type': [], 'event_data': []}\n",
    "            selected_lines = lines # used to select only a subset of lines (debugging)\n",
    "            for line in tqdm(selected_lines, total=len(selected_lines)):\n",
    "                elements = line.split()\n",
    "                \n",
    "                # Don't keep any line before the presence of '---'\n",
    "                if not pass_config_line and '---' not in elements:\n",
    "                    pass_config_line = True\n",
    "                    continue\n",
    "\n",
    "                # If NET:DISPLAY_LIST, process the JSON format\n",
    "                if 'NET:DISPLAY_LIST' in elements:\n",
    "                    json_element = json.loads(elements[-1])\n",
    "\n",
    "                    # Filter to only get the actors that are students\n",
    "                    results = []\n",
    "                    for actor in json_element:\n",
    "                        if 'pz' in actor['id']:\n",
    "                            compressed = {k:v for k,v in actor.items() if k in ['id', 'skin', 'x', 'y']}\n",
    "                            results.append(compressed)\n",
    "\n",
    "                    # If empty, skip the line\n",
    "                    if not results:\n",
    "                        continue\n",
    "                    \n",
    "                    # Update the element\n",
    "                    elements[-1] = json.dumps(results)\n",
    "\n",
    "                # Elements to remove (don't provide information)\n",
    "                for rule in ['bpid', 'Molecule', 'UADDR', 'agentId', 'targetId', 'b2b', 'binb', 'null', 'c2c', 'null', 'c2b']:\n",
    "                    to_be_removed = []\n",
    "                    for element in elements:\n",
    "                        if rule in element:\n",
    "                            to_be_removed.append(element)\n",
    "                            break\n",
    "                    \n",
    "                    for element in to_be_removed:\n",
    "                        elements.remove(element)\n",
    "\n",
    "                # Elements to remove\n",
    "                to_be_removed = []\n",
    "                for element in elements:\n",
    "                    if element in ['id', 'x', 'y', 'pz', 'null']:\n",
    "                        to_be_removed.append(element)\n",
    "\n",
    "                for element in to_be_removed:\n",
    "                    elements.remove(element)\n",
    "\n",
    "                # Identify the events and save it accordingly\n",
    "                if elements[1] == 'NET:DISPLAY_LIST':\n",
    "                    columns['datetime'].append(elements[0])\n",
    "                    columns['event_type'].append('game_update')\n",
    "                    columns['event_data'].append(elements[2])\n",
    "                elif elements[1] == 'Touched':\n",
    "                    columns['datetime'].append(elements[0])\n",
    "                    columns['event_type'].append('touch')\n",
    "                    event_data = {'src': elements[2], 'dst': elements[3]}\n",
    "                    columns['event_data'].append(json.dumps(event_data))\n",
    "                elif 'pz' in elements[1]:\n",
    "                    columns['datetime'].append(elements[0])\n",
    "                    columns['event_type'].append('position')\n",
    "                    event_data = {'id': elements[1], 'x': elements[2], 'y': elements[3]}\n",
    "                    columns['event_data'].append(json.dumps(event_data))\n",
    "\n",
    "                # for i, element in enumerate(elements):\n",
    "                #     if i not in columns:\n",
    "                #         columns[i] = []\n",
    "                #     columns[i].append(element)\n",
    "\n",
    "                # Make sure to add empty elements to columns that don't have them\n",
    "                # for i in range(len(elements), len(columns)):\n",
    "                #     columns[i].append('')\n",
    "\n",
    "            # Convert\n",
    "            df = pd.DataFrame(columns)\n",
    "            if len(df) > 0:\n",
    "                dfs.append(df)\n",
    "    \n",
    "    # Concatenate all dataframes into one\n",
    "    df = pd.concat(dfs)\n",
    "\n",
    "    # Sort by timestamp\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'], format='%H:%M:%S:0%f')\n",
    "    df = df.sort_values(by='datetime')\n",
    "\n",
    "    # Save the dataframe\n",
    "    df.to_csv(output_file, index=False)\n",
    "\n",
    "# Perform the routine\n",
    "# log_preprocessing(DATA_DIR / 'logs' / 'VU_GEM-STEP_NB_2022_Fall_AH_GroupB_Day11_221109_ComputerLogs')\n",
    "for dir in (DATA_DIR / 'logs').iterdir():\n",
    "    if dir.is_dir():\n",
    "        log_preprocessing(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1708702/1708702 [04:11<00:00, 6802.65it/s]\n",
      "100%|██████████| 2118739/2118739 [05:05<00:00, 6946.58it/s]\n",
      "100%|██████████| 727986/727986 [01:48<00:00, 6686.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# Game state reconstruction routines\n",
    "@dataclass\n",
    "class Participant(DataClassJsonMixin):\n",
    "    id: str\n",
    "    position: Tuple[float, float]\n",
    "    state: Literal['scientist'] = 'null'\n",
    "\n",
    "@dataclass\n",
    "class EnvironmentState(DataClassJsonMixin):\n",
    "    sun_state: Optional[bool] = None\n",
    "\n",
    "@dataclass\n",
    "class GameState(DataClassJsonMixin):\n",
    "    participants: Dict[str, Participant] = field(default_factory=dict)\n",
    "    environment: EnvironmentState = field(default_factory=EnvironmentState)\n",
    "\n",
    "def game_state_reconstruction(csv_file: pathlib.Path, period_ms: int):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "\n",
    "    # Output file\n",
    "    output_file = csv_file.parent / 'game_state.csv'\n",
    "    # if output_file.exists():\n",
    "    #     return\n",
    "\n",
    "    # Map from texture to state\n",
    "    texture_to_state = {\n",
    "        'PS_oxygen.png': 'O2',\n",
    "        'PS_water.png': 'H2O',\n",
    "        'PS_carbon_dioxide.png': 'CO2',\n",
    "        'PS_sugar.png': 'Sugar',\n",
    "        'PS_waterthinking.png': 'Thinking_H2O'\n",
    "    }\n",
    "\n",
    "    # Create a game state object\n",
    "    game_state = GameState()\n",
    "    prior_datetime = None\n",
    "    game_data = {'datetime': [], 'state': []}\n",
    "\n",
    "    for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "\n",
    "        # Handle the different kinds of events\n",
    "        if row['event_type'] == 'game_update':\n",
    "            data = json.loads(row['event_data'])\n",
    "\n",
    "            for actor in data:\n",
    "                if 'skin' not in actor:\n",
    "                    continue\n",
    "\n",
    "                if actor['id'] not in game_state.participants:\n",
    "                    state = texture_to_state[actor['skin']]\n",
    "                    p = Participant(id=actor['id'], state=state, position=(0, 0))\n",
    "                    game_state.participants[actor['id']] = p\n",
    "                else:\n",
    "                    p = game_state.participants[actor['id']]\n",
    "                    p.state = texture_to_state[actor['skin']]\n",
    "\n",
    "        elif row['event_type'] == 'touch':\n",
    "            # data = json.loads(row['event_data'])\n",
    "            ...\n",
    "        elif row['event_type'] == 'position':\n",
    "            data = json.loads(row['event_data'])\n",
    "            \n",
    "            if data['id'] not in game_state.participants:\n",
    "                p = Participant(id=data['id'], position=(data['x'], data['y']))\n",
    "                game_state.participants[data['id']] = p\n",
    "            else:\n",
    "                p = game_state.participants[data['id']]\n",
    "                p.position = (data['x'], data['y'])\n",
    "        else:\n",
    "            raise ValueError(f'Unknown event type: {row[\"event_type\"]}')\n",
    "        \n",
    "        # Save the game state\n",
    "        if prior_datetime is None or (row['datetime'] - prior_datetime).total_seconds() >= period_ms:\n",
    "            game_data['datetime'].append(row['datetime'])\n",
    "            game_data['state'].append(game_state.to_json())\n",
    "            prior_datetime = row['datetime']\n",
    "        \n",
    "    # Save the game state\n",
    "    game_data = pd.DataFrame(game_data)\n",
    "    game_data.to_csv(output_file, index=False)\n",
    "\n",
    "# Perform game state reconstruction\n",
    "for dir in (DATA_DIR / 'logs').iterdir():\n",
    "    game_state_reconstruction(dir / 'game_logs.csv', period_ms=0.1)\n",
    "# game_state_reconstruction(DATA_DIR / 'logs' / 'VU_GEM-STEP_NB_2022_Fall_AH_GroupB_Day11_221109_ComputerLogs' / 'game_logs.csv', period_ms=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit ('3.10.0')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e5e6cd7fd8364f1ddd44d19bbb2d15b84b1ac7169dc3dda84591cf51ae30813c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's process the GEM-STEP logs and reconstruct the game state for Photosynthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pathlib\n",
    "import os\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, Literal, Optional, Tuple\n",
    "import json\n",
    "\n",
    "from dataclasses_json import DataClassJsonMixin\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Constants \n",
    "CWD = pathlib.Path(os.path.abspath(\"\"))\n",
    "GIT_ROOT = CWD.parent\n",
    "DATA_DIR = GIT_ROOT / \"data\" / 'SSMVSpring23'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85326/85326 [00:00<00:00, 88104.47it/s]\n",
      "100%|██████████| 2276323/2276323 [00:26<00:00, 85744.74it/s]\n",
      "100%|██████████| 630194/630194 [00:07<00:00, 86356.11it/s]\n",
      "100%|██████████| 3512/3512 [00:00<00:00, 89081.31it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 135957.99it/s]\n",
      "100%|██████████| 163037/163037 [00:01<00:00, 88166.10it/s]\n"
     ]
    }
   ],
   "source": [
    "# Perform log pre-processing (Step #1) (combining and converting .txt to .csv)\n",
    "def log_preprocessing(dir):\n",
    "\n",
    "    output_file = dir / 'game_logs.csv'\n",
    "    # if output_file.exists():\n",
    "    #     return\n",
    "\n",
    "    # Combine all .txt files into one .csv file\n",
    "    txt_files = [file for file in dir.iterdir() if file.suffix == '.txt']\n",
    "    dfs = []\n",
    "    for file in txt_files:\n",
    "        \n",
    "        # Won't work - error loading file\n",
    "        # df = pd.read_csv(file, sep='\\t', header=None)\n",
    "        # dfs.append(df)\n",
    "\n",
    "        with open(file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "            pass_config_line = False\n",
    "            columns = {'datetime': [], 'event_type': [], 'event_data': []}\n",
    "            selected_lines = lines # used to select only a subset of lines (debugging)\n",
    "            for line in tqdm(selected_lines, total=len(selected_lines)):\n",
    "                #Replacing : with blank space because of json error with scientists-birds model\n",
    "                elements = line.replace(': ', ':').split()\n",
    "                \n",
    "                # Don't keep any line before the presence of '---'\n",
    "                if not pass_config_line and '---' not in elements:\n",
    "                    pass_config_line = True\n",
    "                    continue\n",
    "\n",
    "                # If NET:DISPLAY_LIST, process the JSON format\n",
    "                if 'NET:DISPLAY_LIST' in elements:\n",
    "                    json_element = json.loads(elements[-1])\n",
    "\n",
    "                    # Filter to only get the actors that are students\n",
    "                    results = []\n",
    "                    for actor in json_element:\n",
    "                        if 'pz' in actor['id']:\n",
    "                            compressed = {k:v for k,v in actor.items() if k in ['id', 'skin', 'x', 'y']}\n",
    "                            results.append(compressed)\n",
    "\n",
    "                    # If empty, skip the line\n",
    "                    if not results:\n",
    "                        continue\n",
    "                    \n",
    "                    # Update the element\n",
    "                    elements[-1] = json.dumps(results)\n",
    "\n",
    "                # Elements to remove (don't provide information)\n",
    "                for rule in ['bpid', 'Molecule', 'UADDR', 'agentId', 'targetId', 'b2b', 'binb', 'null', 'c2c', 'null', 'c2b']:\n",
    "                    to_be_removed = []\n",
    "                    for element in elements:\n",
    "                        if rule in element:\n",
    "                            to_be_removed.append(element)\n",
    "                            break\n",
    "                    \n",
    "                    for element in to_be_removed:\n",
    "                        elements.remove(element)\n",
    "\n",
    "                # Elements to remove\n",
    "                to_be_removed = []\n",
    "                for element in elements:\n",
    "                    if element in ['id', 'x', 'y', 'pz', 'null']:\n",
    "                        to_be_removed.append(element)\n",
    "\n",
    "                for element in to_be_removed:\n",
    "                    elements.remove(element)\n",
    "\n",
    "                # Identify the events and save it accordingly\n",
    "                if elements[1] == 'NET:DISPLAY_LIST':\n",
    "                    columns['datetime'].append(elements[0])\n",
    "                    columns['event_type'].append('game_update')\n",
    "                    columns['event_data'].append(elements[2])\n",
    "                elif elements[1] == 'Touched':\n",
    "                    columns['datetime'].append(elements[0])\n",
    "                    columns['event_type'].append('touch')\n",
    "                    event_data = {'src': elements[2], 'dst': elements[3]}\n",
    "                    columns['event_data'].append(json.dumps(event_data))\n",
    "                elif 'pz' in elements[1]:\n",
    "                    columns['datetime'].append(elements[0])\n",
    "                    columns['event_type'].append('position')\n",
    "                    event_data = {'id': elements[1], 'x': elements[3], 'y': elements[4]}\n",
    "                    columns['event_data'].append(json.dumps(event_data))\n",
    "\n",
    "                # for i, element in enumerate(elements):\n",
    "                #     if i not in columns:\n",
    "                #         columns[i] = []\n",
    "                #     columns[i].append(element)\n",
    "\n",
    "                # Make sure to add empty elements to columns that don't have them\n",
    "                # for i in range(len(elements), len(columns)):\n",
    "                #     columns[i].append('')\n",
    "\n",
    "            # Convert\n",
    "            df = pd.DataFrame(columns)\n",
    "            if len(df) > 0:\n",
    "                dfs.append(df)\n",
    "    \n",
    "    # Concatenate all dataframes into one\n",
    "    df = pd.concat(dfs)\n",
    "\n",
    "    # Sort by timestamp\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'], format='%H:%M:%S:0%f')\n",
    "    df = df.sort_values(by='datetime')\n",
    "\n",
    "    # Save the dataframe\n",
    "    df.to_csv(output_file, index=False)\n",
    "\n",
    "# Perform the routine\n",
    "# log_preprocessing(DATA_DIR / 'logs' / 'VU_GEM-STEP_NB_2022_Fall_AH_GroupB_Day11_221109_ComputerLogs')\n",
    "for dir in (DATA_DIR / 'logs').iterdir():\n",
    "    if dir.is_dir():\n",
    "        log_preprocessing(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['datetime', 'event_type', 'event_data'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85324/85324 [00:07<00:00, 10900.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['datetime', 'state'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8641/8641 [00:00<00:00, 9001.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['datetime', 'event_type', 'event_data'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2276321/2276321 [02:43<00:00, 13882.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['datetime', 'state'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27207/27207 [00:03<00:00, 8527.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['datetime', 'event_type', 'event_data'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 630192/630192 [00:47<00:00, 13225.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['datetime', 'state'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12734/12734 [00:01<00:00, 8820.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['datetime', 'event_type', 'event_data'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3510/3510 [00:00<00:00, 7395.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['datetime', 'state'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1731/1731 [00:00<00:00, 8521.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['datetime', 'event_type', 'event_data'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163035/163035 [00:16<00:00, 9959.22it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['datetime', 'state'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12818/12818 [00:01<00:00, 9210.19it/s]\n"
     ]
    }
   ],
   "source": [
    "# Game state reconstruction routines\n",
    "@dataclass\n",
    "class Participant(DataClassJsonMixin):\n",
    "    id: str\n",
    "    position: Tuple[float, float]\n",
    "    state: Literal['scientist'] = 'null'\n",
    "\n",
    "@dataclass\n",
    "#class EnvironmentState(DataClassJsonMixin):\n",
    " #   sun_state: Optional[bool] = None\n",
    "\n",
    "@dataclass\n",
    "class GameState(DataClassJsonMixin):\n",
    "    participants: Dict[str, Participant] = field(default_factory=dict)\n",
    "    environment: EnvironmentState = field(default_factory=EnvironmentState)\n",
    "\n",
    "def game_state_reconstruction(csv_file: pathlib.Path, period_ms: int):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "\n",
    "    # Output file\n",
    "    output_file = csv_file.parent / 'game_state.csv'\n",
    "    # if output_file.exists():\n",
    "    #     return\n",
    "\n",
    "    # Map from texture to state\n",
    "    texture_to_state = {\n",
    "        'SF_scientist.png': 'scientist',\n",
    "        'SF_scientistcarrying.png': 'scientist_with_bird',\n",
    "        'SF_scientistcarryinglarger.png': 'scientist_comparing_bigger',\n",
    "        'SF_scientistcarryingsmaller.png': 'scientist_comparing_smaller',\n",
    "    }\n",
    "\n",
    "    # Create a game state object\n",
    "    game_state = GameState()\n",
    "    prior_datetime = None\n",
    "    game_data = {'datetime': [], 'state': []}\n",
    "    print(df.columns)\n",
    "\n",
    "    for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "\n",
    "        if 'event_type' in df.columns:\n",
    "            # Handle the different kinds of events\n",
    "            if row['event_type'] == 'game_update':\n",
    "                data = json.loads(row['event_data'])\n",
    "\n",
    "                for actor in data:\n",
    "                    if 'skin' not in actor:\n",
    "                        continue\n",
    "\n",
    "                    if actor['id'] not in game_state.participants:\n",
    "                        state = texture_to_state[actor['skin']]\n",
    "                        p = Participant(id=actor['id'], state=state, position=(0, 0))\n",
    "                        game_state.participants[actor['id']] = p\n",
    "                    else:\n",
    "                        p = game_state.participants[actor['id']]\n",
    "                        p.state = texture_to_state[actor['skin']]\n",
    "\n",
    "            elif row['event_type'] == 'touch':\n",
    "                # data = json.loads(row['event_data'])\n",
    "                ...\n",
    "            elif row['event_type'] == 'position':\n",
    "                data = json.loads(row['event_data'])\n",
    "                \n",
    "                if data['id'] not in game_state.participants:\n",
    "                    p = Participant(id=data['id'], position=(data['x'], data['y']))\n",
    "                    game_state.participants[data['id']] = p\n",
    "                else:\n",
    "                    p = game_state.participants[data['id']]\n",
    "                    p.position = (data['x'], data['y'])\n",
    "            else:\n",
    "                raise ValueError(f'Unknown event type: {row[\"event_type\"]}')\n",
    "        \n",
    "        # Save the game state\n",
    "        if prior_datetime is None or (row['datetime'] - prior_datetime).total_seconds() >= period_ms:\n",
    "            game_data['datetime'].append(row['datetime'])\n",
    "            game_data['state'].append(game_state.to_json())\n",
    "            prior_datetime = row['datetime']\n",
    "        \n",
    "    # Save the game state\n",
    "    game_data = pd.DataFrame(game_data)\n",
    "    game_data.to_csv(output_file, index=False)\n",
    "\n",
    "# Perform game state reconstruction\n",
    "for subdir in (DATA_DIR / 'logs').iterdir():\n",
    "    if subdir.is_dir():\n",
    "        for csv_file in subdir.glob('*.csv'):\n",
    "            try:\n",
    "                game_state_reconstruction(csv_file, period_ms=0.1)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {csv_file}: {e}\")\n",
    "# game_state_reconstruction(DATA_DIR / 'logs' / 'VU_GEM-STEP_NB_2022_Fall_AH_GroupB_Day11_221109_ComputerLogs' / 'game_logs.csv', period_ms=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit ('3.10.0')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e5e6cd7fd8364f1ddd44d19bbb2d15b84b1ac7169dc3dda84591cf51ae30813c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
